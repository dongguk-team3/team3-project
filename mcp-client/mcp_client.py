"""
MCP Client MVP - ìœ„ì¹˜ ê¸°ë°˜ í• ì¸ ì„œë¹„ìŠ¤
REST API ì„œë²„ + MCP Client + LLM í†µí•©

ì‹¤í–‰ ëª¨ë“œ:
1. API ì„œë²„ ëª¨ë“œ: python mcp_client.py --mode api
2. í…ŒìŠ¤íŠ¸ ëª¨ë“œ: python mcp_client.py --mode test
"""

import asyncio
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from typing import Optional, Dict, Any, List
import json
import sys
import os
import argparse

# Prompt Filter í†µí•©
from prompt_filter import LLMPipeline

# RAG í†µí•©
from rag_module import RAGPipeline

# ë¦¬ë·° ìˆ˜ì§‘ ì‹œìŠ¤í…œ í†µí•© (Discount_MAP_server í´ë”ì—ì„œ import)
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../mcp-server'))
from Discount_MAP_server.review_generator import ReviewGenerator  # type: ignore

# FastAPI ê´€ë ¨ (API ëª¨ë“œì—ì„œë§Œ ì‚¬ìš©)
try:
    from fastapi import FastAPI, HTTPException, Depends, Header
    from fastapi.middleware.cors import CORSMiddleware
    from pydantic import BaseModel
    from fastapi.security import APIKeyHeader
    import uvicorn
    FASTAPI_AVAILABLE = True
except ImportError:
    FASTAPI_AVAILABLE = False
    print("âš ï¸  FastAPIê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install fastapi uvicorn' ì‹¤í–‰")

# OpenAI í†µí•©
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    OpenAI = None
    print("âš ï¸  OpenAIê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LLM ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install openai' ì‹¤í–‰")

# ê²½ë¡œë¡œ íƒìƒ‰ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¦¬
import os

# API í‚¤ (íŒ€ì›ë“¤ê³¼ ê³µìœ í•  ë¹„ë°€ í‚¤)
API_KEY = os.getenv("API_KEY", "OSS_TEAM_SECRET_KEY_2025")

# OpenAI API í‚¤ ë¡œë“œ
def load_openai_api_key():
    """OPENAI_API.txt íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ"""
    try:
        key_file = os.path.join(os.path.dirname(__file__), "OPENAI_API.txt")
        with open(key_file, 'r') as f:
            key = f.read().strip()
            if key and key != "YOUR_API_KEY_HERE":
                return key
    except FileNotFoundError:
        pass
    
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì‹œë„
    return os.getenv("OPENAI_API_KEY", None)

# OpenAI API ì„¤ì •
OPENAI_API_KEY = load_openai_api_key()
OPENAI_CLIENT = None

if OPENAI_API_KEY and OPENAI_AVAILABLE:
    try:
        OPENAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY)
        print(f"âœ… OpenAI API í‚¤ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸  OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
else:
    print(f"âš ï¸  OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


# ==================== MCP Server í´ë˜ìŠ¤ë“¤ ====================

class LocationServer:
    """ìœ„ì¹˜ ê¸°ë°˜ ìƒì  ê²€ìƒ‰ ì„œë²„"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.server_path = "/opt/conda/envs/team/OSS/mcp-server/Discount_MAP_server/location_server.py"
    
    async def search_stores(self, latitude: float, longitude: float, query: str) -> Dict[str, Any]:
        """
        ìƒì  ê²€ìƒ‰ (MCP Server í˜¸ì¶œ)
        
        Args:
            latitude: ìœ„ë„
            longitude: ê²½ë„
            query: ê²€ìƒ‰ ì¿¼ë¦¬ (ì˜ˆ: "ìŒì‹ì ", "ì¹´í˜")
        
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        server_params = StdioServerParameters(
            command="python",
            args=[self.server_path],
            env={"PYTHONPATH": "/opt/conda/envs/team/lib/python3.11/site-packages"}
        )
        
        try:
            async with stdio_client(server_params) as (read, write):
                async with ClientSession(read, write) as session:
                    await session.initialize()
                    
                    # search_nearby_stores ë„êµ¬ í˜¸ì¶œ
                    result = await session.call_tool(
                        "search_nearby_stores",
                        {
                            "latitude": latitude,
                            "longitude": longitude,
                            "category": query
                        }
                    )
                    
                    # ê²°ê³¼ íŒŒì‹±
                    if result.content and len(result.content) > 0:
                        response_text = result.content[0].text if hasattr(result.content[0], 'text') else str(result.content[0])
                        parsed_result = json.loads(response_text)
                        print(f"   MCP ì„œë²„ ì‘ë‹µ: {parsed_result.get('message', 'N/A')}")
                        print(f"   ê°€ê²Œ ìˆ˜: {len(parsed_result.get('stores', []))}ê°œ")
                        return parsed_result
                    
                    print("   âš ï¸ MCP ì„œë²„ì—ì„œ ë¹ˆ ì‘ë‹µ ë°›ìŒ")
                    return {"stores": [], "error": "ê²°ê³¼ ì—†ìŒ"}
                    
        except Exception as e:
            print(f"   âŒ MCP í†µì‹  ì˜¤ë¥˜: {e}")
            return {
                "stores": [],
                "error": f"MCP ì„œë²„ í†µì‹  ì˜¤ë¥˜: {str(e)}",
                "details": str(e)
            }
    
    ## ë””ë²„ê¹…ìš© í•¨ìˆ˜
    async def test_connection(self, server_params: StdioServerParameters):
        """MCP ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        print("=" * 60)
        print("ğŸš€ MCP Client MVP í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 60)
        
        try:
            print(f"ğŸ”Œ MCP ì„œë²„ì— ì—°ê²° ì¤‘...")
            
            # stdio_clientë¡œ ì„œë²„ì™€ ì—°ê²°
            async with stdio_client(server_params) as (read, write):
                async with ClientSession(read, write) as session:
                    # ì„¸ì…˜ ì´ˆê¸°í™”
                    init_result = await session.initialize()
                    print(f"âœ… MCP ì„œë²„ ì—°ê²° ì„±ê³µ!")
                    
                    # ì„œë²„ ì •ë³´ ì¶œë ¥
                    print(f"\nğŸ“‹ ì„œë²„ ì •ë³´:")
                    print(f"  - ì„œë²„ ì´ë¦„: {init_result.serverInfo.name}")
                    print(f"  - í”„ë¡œí† ì½œ ë²„ì „: {init_result.protocolVersion}")
                    
                    # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ì¡°íšŒ
                    print(f"\nğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡:")
                    tools_list = await session.list_tools()
                    
                    if not tools_list.tools:
                        print("  ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        return
                    
                    for i, tool in enumerate(tools_list.tools, 1):
                        print(f"  {i}. {tool.name}")
                        if hasattr(tool, 'description') and tool.description:
                            print(f"     ì„¤ëª…: {tool.description}")
                        if hasattr(tool, 'inputSchema'):
                            print(f"     íŒŒë¼ë¯¸í„°: {tool.inputSchema}")
                    
                    # ì²« ë²ˆì§¸ ë„êµ¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
                    if tools_list.tools:
                        first_tool = tools_list.tools[0]
                        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ë„êµ¬ ì‹¤í–‰: {first_tool.name}")
                        
                        # ë„êµ¬ì— ë”°ë¼ ì ì ˆí•œ íŒŒë¼ë¯¸í„° ì„¤ì •
                        test_args = self._get_test_arguments(first_tool.name)
                        
                        if test_args is not None:
                            print(f"   íŒŒë¼ë¯¸í„°: {json.dumps(test_args, ensure_ascii=False, indent=2)}")
                            
                            try:
                                result = await session.call_tool(first_tool.name, test_args)
                                print(f"âœ… ë„êµ¬ ì‹¤í–‰ ì„±ê³µ!")
                                print(f"   ê²°ê³¼:")
                                for content in result.content:
                                    if hasattr(content, 'text'):
                                        print(f"   {content.text}")
                                    else:
                                        print(f"   {content}")
                            except Exception as e:
                                print(f"âš ï¸  ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        else:
                            print(f"   (ì´ ë„êµ¬ëŠ” í•„ìˆ˜ íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•˜ì—¬ ìŠ¤í‚µí•©ë‹ˆë‹¤)")
                    
                    print("\n" + "=" * 60)
                    print("âœ… MCP Client MVP í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
                    print("=" * 60)
            
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            traceback.print_exc()
    
    ## ë””ë²„ê¹…ìš© í•¨ìˆ˜
    def _get_test_arguments(self, tool_name: str) -> Optional[dict]:
        """ë„êµ¬ë³„ í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„° ë°˜í™˜"""
        # ìì²´ ìœ„ì¹˜ ì„œë²„ ë„êµ¬ë“¤
        if tool_name == "search_nearby_stores":
            return {
                "latitude": 37.5665,   # ì„œìš¸ ì‹œì²­ ìœ„ë„
                "longitude": 126.9780, # ì„œìš¸ ì‹œì²­ ê²½ë„
                "category": "ìŒì‹ì "
            }
        
        if tool_name == "get_store_info":
            return {
                "store_id": "store_001"
            }
        
        # ê¸°ë³¸ì ìœ¼ë¡œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
        return {}


class DiscountServer:
    """í• ì¸ ì •ë³´ ìˆ˜ì§‘ ì„œë²„ (ì¶”í›„ êµ¬í˜„ ì˜ˆì •)"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        # TODO: ì‹¤ì œ í• ì¸ ì •ë³´ MCP ì„œë²„ ê²½ë¡œ ì„¤ì •
        self.server_path = "/opt/conda/envs/team/OSS/mcp-server/discount_server.py"
        self.is_implemented = False
    
    async def get_discounts(
        self, 
        stores: List[Dict], 
        user_profile: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ì—¬ëŸ¬ ê°€ê²Œì˜ í• ì¸ ì •ë³´ ì¼ê´„ ì¡°íšŒ (ì‚¬ìš©ì í”„ë¡œí•„ ê¸°ë°˜)
        
        Args:
            stores: ê°€ê²Œ ëª©ë¡ (LocationServer ê²°ê³¼)
            user_profile: ì‚¬ìš©ì í”„ë¡œí•„ (PatternAnalysisServer ê²°ê³¼)
                - telecom: í†µì‹ ì‚¬
                - cards: ë³´ìœ  ì¹´ë“œ ëª©ë¡
                - memberships: ë©¤ë²„ì‹­ ëª©ë¡
        
        Returns:
            ê°€ê²Œë³„ í• ì¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        if not self.is_implemented:
            # TODO: ì‹¤ì œ MCP ì„œë²„ êµ¬í˜„ í›„ ì œê±°
            # Mock ë°ì´í„°: ê° ê°€ê²Œë³„ í• ì¸ ì •ë³´ ìƒì„±
            discounts_by_store = {}
            
            for store in stores[:5]:  # ìƒìœ„ 5ê°œë§Œ Mock
                store_id = store.get("id", "unknown")
                store_name = store.get("name", "ì•Œ ìˆ˜ ì—†ìŒ")
                
                # Mock í• ì¸ ìƒì„±
                mock_discounts = []
                
                # í†µì‹ ì‚¬ í• ì¸ (Mock)
                telecom = user_profile.get("telecom", "")
                if telecom in ["SKT", "KT", "LG U+"]:
                    mock_discounts.append({
                        "type": "telecom",
                        "provider": telecom,
                        "rate": 20,
                        "description": f"{telecom} í†µì‹ ì‚¬ ì œíœ´ 20% í• ì¸"
                    })
                
                # ì¹´ë“œ í• ì¸ (Mock)
                cards = user_profile.get("cards", {})
                primary_card = cards.get("primary", "")
                if primary_card:
                    mock_discounts.append({
                        "type": "card",
                        "provider": primary_card,
                        "rate": 10,
                        "description": f"{primary_card} 10% ì¦‰ì‹œí• ì¸"
                    })
                
                # ìµœëŒ€ í• ì¸ìœ¨ ê³„ì‚°
                max_discount = max([d["rate"] for d in mock_discounts], default=0)
                
                discounts_by_store[store_id] = {
                    "store_id": store_id,
                    "store_name": store_name,
                    "discounts": mock_discounts,
                    "max_discount": max_discount,
                    "best_payment": mock_discounts[0] if mock_discounts else None
                }
            
            return {
                "message": "âš ï¸ í• ì¸ ì •ë³´ ì„œë²„ëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (Mock ë°ì´í„°).",
                "discounts_by_store": discounts_by_store,
                "total_stores_analyzed": len(discounts_by_store)
            }
        
        # TODO: ì‹¤ì œ MCP ì„œë²„ í˜¸ì¶œ ë¡œì§ êµ¬í˜„
        pass


class RecommendationServer:
    """ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì„œë²„ (ì¶”í›„ êµ¬í˜„ ì˜ˆì •)"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        # TODO: ì‹¤ì œ ì¶”ì²œ MCP ì„œë²„ ê²½ë¡œ ì„¤ì •
        self.server_path = "/opt/conda/envs/team/OSS/mcp-server/recommendation_server.py"
        self.is_implemented = False
    
    async def get_recommendations(
        self, 
        user_id: str,
        user_profile: Dict[str, Any],
        user_preferences: Dict[str, Any],
        stores: List[Dict],
        discounts: Dict[str, Any],
        context: Dict = None
    ) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ë§ì¶¤ ì¶”ì²œ ìƒì„± (ëª¨ë“  MCP Server ê²°ê³¼ ì¢…í•©)
        
        Args:
            user_id: ì‚¬ìš©ì ID
            user_profile: ì‚¬ìš©ì í”„ë¡œí•„ (í†µì‹ ì‚¬, ì¹´ë“œ ë“±)
            user_preferences: ì‚¬ìš©ì ì„ í˜¸ë„ (ì„ í˜¸ ì¹´í…Œê³ ë¦¬, í‰ê·  ì˜ˆì‚° ë“±)
            stores: ìƒì  ëª©ë¡ (LocationServer)
            discounts: í• ì¸ ì •ë³´ (DiscountServer)
            context: ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (ì‹œê°„, ë‚ ì”¨ ë“±)
        
        Returns:
            ì¶”ì²œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (ìˆœìœ„ë³„ ì ìˆ˜ í¬í•¨)
        """
        if not self.is_implemented:
            # TODO: ì‹¤ì œ MCP ì„œë²„ êµ¬í˜„ í›„ ì œê±°
            # Mock: í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì‹œë®¬ë ˆì´ì…˜
            
            discounts_data = discounts.get("discounts_by_store", {})
            preferred_categories = user_preferences.get("preferred_categories", [])
            avg_budget = user_preferences.get("avg_budget", 15000)
            
            scored_stores = []
            
            for store in stores:
                store_id = store.get("id", "")
                store_name = store.get("name", "ì•Œ ìˆ˜ ì—†ìŒ")
                category = store.get("category_name", "")
                distance = store.get("distance", 999999)
                
                # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° (Mock)
                score = 0.0
                breakdown = {}
                
                # [1] Content-Based Filtering (40%)
                content_score = 0.0
                # A. ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ (25ì )
                if any(cat in category for cat in preferred_categories):
                    content_score += 0.25
                # B. ê±°ë¦¬ ì ìˆ˜ (15ì ) - ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ìŒ
                distance_score = max(0, 1 - (distance / 1000)) * 0.15
                content_score += distance_score
                
                breakdown["content_based"] = content_score * 0.4
                score += content_score * 0.4
                
                # [2] Collaborative Filtering (30%) - Mock: ëœë¤
                collab_score = 0.15  # Mock: í‰ê·  ì ìˆ˜
                breakdown["collaborative"] = collab_score * 0.3
                score += collab_score * 0.3
                
                # [3] Discount Optimization (30%)
                discount_info = discounts_data.get(store_id, {})
                max_discount = discount_info.get("max_discount", 0)
                discount_score = min(max_discount / 30, 1.0) * 0.3
                breakdown["discount"] = discount_score
                score += discount_score
                
                # ì¶”ì²œ ì´ìœ  ìƒì„±
                reasons = []
                if any(cat in category for cat in preferred_categories):
                    reasons.append(f"ì„ í˜¸í•˜ì‹œëŠ” {category} ì¹´í…Œê³ ë¦¬")
                if max_discount > 0:
                    best_payment = discount_info.get("best_payment", {})
                    provider = best_payment.get("provider", "") if best_payment else ""
                    reasons.append(f"{provider} {max_discount}% í• ì¸")
                if distance < 300:
                    reasons.append(f"ê°€ê¹Œìš´ ê±°ë¦¬ ({distance}m)")
                
                scored_stores.append({
                    "rank": 0,  # ë‚˜ì¤‘ì— ì •ë ¬ í›„ ì„¤ì •
                    "store": store,
                    "score": round(score, 2),
                    "score_breakdown": breakdown,
                    "discount_info": discount_info,
                    "recommendation_reason": ", ".join(reasons) if reasons else "ì£¼ë³€ ì¸ê¸° ë§¤ì¥"
                })
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            scored_stores.sort(key=lambda x: x["score"], reverse=True)
            
            # ìˆœìœ„ ë¶€ì—¬
            for idx, item in enumerate(scored_stores, 1):
                item["rank"] = idx
            
            return {
                "message": "âš ï¸ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì„œë²„ëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (Mock ì•Œê³ ë¦¬ì¦˜).",
                "recommendations": scored_stores[:10],
                "total_candidates": len(stores),
                "algorithm": "HybridRecommender (Mock)",
                "weights": {
                    "content_based": 0.4,
                    "collaborative": 0.3,
                    "discount": 0.3
                }
            }
        
        # TODO: ì‹¤ì œ MCP ì„œë²„ í˜¸ì¶œ ë¡œì§ êµ¬í˜„
        pass


class PatternAnalysisServer:
    """ê°œì¸í™” ì†Œë¹„ íŒ¨í„´ ë¶„ì„ ì„œë²„ (ì¶”í›„ êµ¬í˜„ ì˜ˆì •)"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        # TODO: ì‹¤ì œ íŒ¨í„´ ë¶„ì„ MCP ì„œë²„ ê²½ë¡œ ì„¤ì •
        self.server_path = "/opt/conda/envs/team/OSS/mcp-server/pattern_server.py"
        self.is_implemented = False
    
    async def analyze_pattern(self, user_id: str) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì†Œë¹„ íŒ¨í„´ ë¶„ì„ (ê°œì¸í™” DB ì¡°íšŒ)
        
        Args:
            user_id: ì‚¬ìš©ì ID
        
        Returns:
            ì‚¬ìš©ì í”„ë¡œí•„ + ì„ í˜¸ë„ ë¶„ì„ ê²°ê³¼
        """
        if not self.is_implemented:
            # TODO: ì‹¤ì œ MCP ì„œë²„ êµ¬í˜„ í›„ ì œê±°
            # Mock: ì‚¬ìš©ì í”„ë¡œí•„ + ê°€ê³„ë¶€ ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜
            
            return {
                "message": "âš ï¸ íŒ¨í„´ ë¶„ì„ ì„œë²„ëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (Mock ë°ì´í„°).",
                "user_id": user_id,
                
                # ì´ˆê¸° í”„ë¡œí•„ (ì•± ì„¤ì¹˜ ì‹œ ì…ë ¥ë°›ì€ ë°ì´í„°)
                "profile": {
                    "telecom": "SKT",
                    "cards": {
                        "primary": "ì‹ í•œì¹´ë“œ",
                        "secondary": "ì‚¼ì„±ì¹´ë“œ"
                    },
                    "memberships": ["CJ ONE", "OKìºì‰¬ë°±"]
                },
                
                # ì„ í˜¸ë„ (ê°€ê³„ë¶€ ë¶„ì„ ê²°ê³¼)
                "preferences": {
                    "preferred_categories": ["í•œì‹", "ì¼ì‹", "ì¹´í˜"],
                    "avg_budget": 15000,
                    "price_range": {
                        "min": 10000,
                        "max": 20000
                    },
                    "visit_patterns": {
                        "times": ["ì ì‹¬", "ì €ë…"],
                        "days": ["ê¸ˆìš”ì¼", "í† ìš”ì¼"]
                    }
                },
                
                # í†µê³„ ì •ë³´
                "stats": {
                    "total_transactions": 45,
                    "total_spent": 675000,
                    "avg_per_transaction": 15000,
                    "most_visited_category": "í•œì‹"
                }
            }
        
        # TODO: ì‹¤ì œ MCP ì„œë²„ í˜¸ì¶œ ë¡œì§ êµ¬í˜„
        pass


# ============================================================
# LLM í†µí•© ë ˆì´ì–´
# ============================================================

class LLMEngine:
    """LLM ì—”ì§„ (OpenAI + RAG)"""
    
    def __init__(self):
        """
        ì´ˆê¸°í™”
        """
        self.prompt_pipeline = LLMPipeline()
        self.rag_pipeline = RAGPipeline(use_openai_embeddings=False)
        self.location_server = LocationServer()
        self.discount_server = DiscountServer()
        self.recommendation_server = RecommendationServer()
        self.pattern_server = PatternAnalysisServer()
        
        # Mock ë¦¬ë·° ìƒì„±ê¸° ì‚¬ìš©
        print("âš™ï¸  ë¦¬ë·° ìˆ˜ì§‘: Mock ìƒì„±ê¸° (ê°œë°œìš©)")
        self.review_generator = ReviewGenerator()
        
        # OpenAI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        self.openai_available = OPENAI_AVAILABLE and OPENAI_API_KEY and OPENAI_CLIENT
        self.openai_client = OPENAI_CLIENT
    
    async def process_query(
        self,
        user_query: str,
        latitude: float,
        longitude: float,
        user_id: str,  # í•„ìˆ˜ë¡œ ë³€ê²½!
        context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬ (ìˆ˜ì •ëœ ì•„í‚¤í…ì²˜)
        
        ì•„í‚¤í…ì²˜ íë¦„:
        1. Prompt Filter
        2. PatternAnalysisServer (í•­ìƒ)
        3. LocationServer & DiscountServer (ë³‘ë ¬, í•­ìƒ)
        4. RecommendationServer (í•­ìƒ, ëª¨ë“  ê²°ê³¼ ì¢…í•©)
        5. RAG
        6. OpenAI LLM
        
        Args:
            user_query: ì‚¬ìš©ì ì§ˆë¬¸
            latitude: ìœ„ë„
            longitude: ê²½ë„
            user_id: ì‚¬ìš©ì ID (í•„ìˆ˜!)
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (ì„ íƒ)
        
        Returns:
            LLM ì‘ë‹µ
        """
        print("\n" + "="*60)
        print(f"ğŸ¯ LLM ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘")
        print(f"   ì‚¬ìš©ì: {user_id}")
        print(f"   ì§ˆë¬¸: {user_query}")
        print(f"   ìœ„ì¹˜: ({latitude}, {longitude})")
        print("="*60)
        
        # [1ë‹¨ê³„] Prompt Filtering (ë„ë©”ì¸ ì œí•œ)
        print(f"\n[1/6] ğŸ›¡ï¸  Prompt Filter ê²€ì¦ ì¤‘...")
        validation_result = self.prompt_pipeline.process(
            user_query,
            context={
                "location": f"ìœ„ë„ {latitude}, ê²½ë„ {longitude}",
                "user_id": user_id
            }
        )
        
        if not validation_result["success"]:
            print(f"âŒ Prompt Filter ê±°ë¶€: {validation_result['message']}")
            return {
                "success": False,
                "error": validation_result["message"],
                "response": validation_result["message"]
            }
        
        print(f"âœ… Prompt Filter í†µê³¼")
        
        # [2ë‹¨ê³„] MCP Servers í˜¸ì¶œ (ìˆœì°¨ì , ì˜ì¡´ì„± ìˆìŒ)
        mcp_results = {}
        
        # 2-1. PatternAnalysisServer (í•­ìƒ, ì œì¼ ë¨¼ì €)
        print(f"\n[2/6] ğŸ“Š PatternAnalysisServer í˜¸ì¶œ ì¤‘...")
        pattern_result = await self.pattern_server.analyze_pattern(user_id)
        mcp_results["pattern"] = pattern_result
        
        # ì‚¬ìš©ì í”„ë¡œí•„ ë° ì„ í˜¸ë„ ì¶”ì¶œ
        user_profile = pattern_result.get("profile", {})
        user_preferences = pattern_result.get("preferences", {})
        print(f"âœ… ì‚¬ìš©ì í”„ë¡œí•„ ë¡œë“œ ì™„ë£Œ")
        print(f"   í†µì‹ ì‚¬: {user_profile.get('telecom', 'N/A')}")
        print(f"   ì£¼ì¹´ë“œ: {user_profile.get('cards', {}).get('primary', 'N/A')}")
        print(f"   ì„ í˜¸ ì¹´í…Œê³ ë¦¬: {user_preferences.get('preferred_categories', [])}")
        
        # 2-2. LocationServer (í•­ìƒ í˜¸ì¶œ)
        print(f"\n[3/6] ğŸ“ LocationServer í˜¸ì¶œ ì¤‘...")
        
        # user_queryì—ì„œ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        category_keywords = ["ì¹´í˜", "ìŒì‹ì ", "ë§›ì§‘", "ì‹ë‹¹", "ë ˆìŠ¤í† ë‘", "í•œì‹", "ì¤‘ì‹", "ì¼ì‹", "ì–‘ì‹", "ë¶„ì‹"]
        search_category = "ì¹´í˜"  # ê¸°ë³¸ê°’
        for keyword in category_keywords:
            if keyword in user_query:
                search_category = keyword
                break
        
        print(f"   ê²€ìƒ‰ ì¹´í…Œê³ ë¦¬: {search_category}")
        
        location_result = await self.location_server.search_stores(
            latitude=latitude,
            longitude=longitude,
            query=search_category  # ë‹¨ìˆœ í‚¤ì›Œë“œë§Œ ì „ë‹¬
        )
        mcp_results["location"] = location_result
        
        stores = location_result.get("stores", [])
        print(f"âœ… ì£¼ë³€ ìƒì  ê²€ìƒ‰ ì™„ë£Œ: {len(stores)}ê°œ ë°œê²¬")
        
        # 2-2-1. ë¦¬ë·° ìˆ˜ì§‘ (Mock ìƒì„±)
        if stores:
            top_stores = stores[:10]
            
            # Mock ë¦¬ë·° ìƒì„±
            print(f"\n[3.5/6] ğŸ“ Mock ë¦¬ë·° ìƒì„± ì¤‘...")
            print(f"   ëŒ€ìƒ: ìƒìœ„ 10ê°œ ê°€ê²Œ")
            print(f"   ê°€ê²Œë‹¹ ë¦¬ë·°: 3ê°œì”©")
            
            enriched_result = self.review_generator.generate_stores_with_reviews(
                stores=top_stores,
                reviews_per_store=3
            )
            
            # ì›ë³¸ stores ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            for i, enriched_store in enumerate(enriched_result['stores']):
                stores[i] = enriched_store
            
            print(f"âœ… Mock ë¦¬ë·° ìƒì„± ì™„ë£Œ: {enriched_result['total_reviews']}ê°œ")
        
        # 2-3. DiscountServer (í•­ìƒ í˜¸ì¶œ, LocationServer ê²°ê³¼ + ì‚¬ìš©ì í”„ë¡œí•„ ì‚¬ìš©)
        print(f"\n[4/6] ğŸ’° DiscountServer í˜¸ì¶œ ì¤‘...")
        discount_result = await self.discount_server.get_discounts(
            stores=stores,
            user_profile=user_profile
        )
        mcp_results["discount"] = discount_result
        
        discounts_count = len(discount_result.get("discounts_by_store", {}))
        print(f"âœ… í• ì¸ ì •ë³´ ë¶„ì„ ì™„ë£Œ: {discounts_count}ê°œ ê°€ê²Œ")
        
        # 2-4. RecommendationServer (í•­ìƒ í˜¸ì¶œ, ëª¨ë“  ì •ë³´ ì¢…í•©)
        print(f"\n[5/6] ğŸ¯ RecommendationServer í˜¸ì¶œ ì¤‘...")
        recommendation_result = await self.recommendation_server.get_recommendations(
            user_id=user_id,
            user_profile=user_profile,
            user_preferences=user_preferences,
            stores=stores,
            discounts=discount_result,
            context=context
        )
        mcp_results["recommendation"] = recommendation_result
        
        recommendations = recommendation_result.get("recommendations", [])
        print(f"âœ… ì¶”ì²œ ì™„ë£Œ: Top-{len(recommendations)} ìƒì„±")
        
        # [3ë‹¨ê³„] RAG (ë²¡í„° DB ìƒì„± ë° ê²€ìƒ‰) - ìŠ¤í…
        print(f"\n[6/6] ğŸ” RAG ì²˜ë¦¬ ì¤‘...")
        rag_result = self.rag_pipeline.process(
            user_query=user_query,
            mcp_results=mcp_results,
            top_k=3,
            session_id=user_id
        )
        print(f"âœ… RAG ì²˜ë¦¬ ì™„ë£Œ (ìŠ¤í… ëª¨ë“œ)")
        
        # [4ë‹¨ê³„] OpenAI LLM í˜¸ì¶œ (ì‹¤ì œ êµ¬í˜„)
        print(f"\nğŸ¤– OpenAI LLM í˜¸ì¶œ ì¤‘...")
        if self.openai_available:
            response = await self._call_openai_llm(
                user_query=user_query,
                llm_context=rag_result["llm_context"],
                validation_result=validation_result
            )
            print(f"âœ… LLM ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        else:
            # OpenAI ì—†ìœ¼ë©´ Mock ì‘ë‹µ
            response = self._generate_mock_response(mcp_results)
            print(f"âš ï¸  OpenAI ì—†ìŒ â†’ Mock ì‘ë‹µ ìƒì„±")
        
        print("\n" + "="*60)
        print(f"âœ… ì¿¼ë¦¬ ì²˜ë¦¬ ì™„ë£Œ")
        print("="*60 + "\n")
        
        return {
            "success": True,
            "query": user_query,
            "response": response,
            "mcp_results": mcp_results,
            "rag_result": rag_result
        }
    
    async def _call_openai_llm(
        self,
        user_query: str,
        llm_context: str,
        validation_result: Dict
    ) -> str:
        """
        OpenAI LLM í˜¸ì¶œ (OpenAI ê³µì‹ ë¬¸ì„œ ê¸°ì¤€)
        
        Args:
            user_query: ì‚¬ìš©ì ì§ˆë¬¸
            llm_context: RAGë¡œ ìƒì„±ëœ ì»¨í…ìŠ¤íŠ¸
            validation_result: Prompt Filter ê²°ê³¼
        
        Returns:
            LLM ìƒì„± ì‘ë‹µ
        """
        try:
            # Prompt Filterì—ì„œ ìƒì„±í•œ messages ì‚¬ìš©
            llm_input = validation_result["llm_input"]
            
            # ë©”ì‹œì§€ êµ¬ì„± (OpenAI ê¶Œì¥ ë°©ì‹)
            messages = []
            
            # 1. System Message: ì—­í•  ì •ì˜
            system_message = llm_input["messages"][0]["content"]
            messages.append({
                "role": "system",
                "content": system_message
            })
            
            # 2. System Message: RAG ì»¨í…ìŠ¤íŠ¸ (ê²€ìƒ‰ëœ ì •ë³´)
            messages.append({
                "role": "system",
                "content": f"""[ê²€ìƒ‰ëœ ì •ë³´]
{llm_context}

[ì§€ì¹¨]
- ìœ„ ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
- ì •ë³´ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  "ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
- í• ì¸ ì •ë³´ê°€ ìˆë‹¤ë©´ ëª…í™•í•˜ê²Œ ê°•ì¡°í•˜ì„¸ìš”.
- ê±°ë¦¬ ì •ë³´ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì•ˆë‚´í•˜ì„¸ìš”.
- ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."""
            })
            
            # 3. User Message: ì‚¬ìš©ì ì§ˆë¬¸
            messages.append({
                "role": "user",
                "content": user_query
            })
            
            # OpenAI API í˜¸ì¶œ (ê³µì‹ ë¬¸ì„œ ê¸°ì¤€)
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo-1106",  # ìµœì‹  ëª¨ë¸ (JSON mode ì§€ì›)
                messages=messages,
                temperature=0.7,  # ì°½ì˜ì„± (0.0 ~ 2.0)
                max_tokens=800,   # ìµœëŒ€ í† í° ìˆ˜
                top_p=1.0,        # Nucleus sampling
                frequency_penalty=0.0,  # ë°˜ë³µ ê°ì†Œ
                presence_penalty=0.0,   # ì£¼ì œ ë‹¤ì–‘ì„±
                # response_format={"type": "text"}  # ë˜ëŠ” "json_object"
            )
            
            # ì‘ë‹µ ì¶”ì¶œ
            assistant_message = response.choices[0].message.content
            
            # í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…
            usage = response.usage
            print(f"ğŸ’° í† í° ì‚¬ìš©ëŸ‰: ì…ë ¥ {usage.prompt_tokens}, ì¶œë ¥ {usage.completion_tokens}, ì´ {usage.total_tokens}")
            
            return assistant_message
            
        except Exception as e:
            # ìƒì„¸í•œ ì—ëŸ¬ ì²˜ë¦¬
            error_type = type(e).__name__
            error_message = str(e)
            
            print(f"âŒ OpenAI API ì˜¤ë¥˜ [{error_type}]: {error_message}")
            
            # ì‚¬ìš©ì ì¹œí™”ì  ì—ëŸ¬ ë©”ì‹œì§€
            if "rate_limit" in error_message.lower():
                return "âš ï¸ ì¼ì‹œì ìœ¼ë¡œ ìš”ì²­ì´ ë§ì•„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            elif "invalid_api_key" in error_message.lower():
                return "âš ï¸ API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
            elif "insufficient_quota" in error_message.lower():
                return "âš ï¸ API ì‚¬ìš©ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
            else:
                return f"âš ï¸ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n(ì˜¤ë¥˜: {error_type})"
    
    def _generate_mock_response(self, mcp_results: Dict) -> str:
        """ì„ì‹œ ì‘ë‹µ ìƒì„± (OpenAI ì—†ì„ ë•Œ)"""
        # ì¶”ì²œ ê²°ê³¼ ì‚¬ìš©
        recommendation_data = mcp_results.get("recommendation", {})
        recommendations = recommendation_data.get("recommendations", [])
        
        if recommendations:
            response = f"ğŸ¯ ë§ì¶¤ ì¶”ì²œ ê²°ê³¼ (Top {len(recommendations[:5])}):\n\n"
            
            for item in recommendations[:5]:
                rank = item.get("rank", 0)
                store = item.get("store", {})
                score = item.get("score", 0)
                reason = item.get("recommendation_reason", "")
                discount_info = item.get("discount_info", {})
                max_discount = discount_info.get("max_discount", 0)
                
                response += f"{rank}. {store.get('name', 'ì•Œ ìˆ˜ ì—†ìŒ')} â­ {score:.2f}ì \n"
                response += f"   ğŸ“ {store.get('address', 'ì£¼ì†Œ ì •ë³´ ì—†ìŒ')}\n"
                response += f"   ğŸ“ {store.get('distance', '?')}m\n"
                
                if max_discount > 0:
                    response += f"   ğŸ’° ìµœëŒ€ {max_discount}% í• ì¸ ê°€ëŠ¥!\n"
                
                if reason:
                    response += f"   ğŸ’¡ ì¶”ì²œ ì´ìœ : {reason}\n"
                
                response += "\n"
            
            response += "\nğŸ’¡ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ë©´ ë” ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µì´ ìƒì„±ë©ë‹ˆë‹¤."
        else:
            # Fallback: Location ë°ì´í„° ì‚¬ìš©
            location_data = mcp_results.get("location", {})
            stores = location_data.get("stores", [])
            
            if stores:
                response = f"ê·¼ì²˜ì—ì„œ {len(stores)}ê°œì˜ ì¥ì†Œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n"
                for i, store in enumerate(stores[:3], 1):
                    response += f"{i}. {store.get('name', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n"
                    response += f"   ğŸ“ {store.get('address', 'ì£¼ì†Œ ì •ë³´ ì—†ìŒ')}\n"
                    response += f"   ğŸ“ {store.get('distance', '?')}m\n\n"
            else:
                response = "ì£„ì†¡í•©ë‹ˆë‹¤. ê·¼ì²˜ì—ì„œ ì¥ì†Œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        return response


# ============================================================
# REST API ì„œë²„ ëª¨ë“œ (FastAPI)
# ============================================================

# Pydantic ëª¨ë¸ (API ìš”ì²­/ì‘ë‹µ)
if FASTAPI_AVAILABLE:
    class RecommendRequest(BaseModel):
        """LLM ê¸°ë°˜ ì¶”ì²œ ìš”ì²­ ëª¨ë¸"""
        query: str
        latitude: float
        longitude: float
        user_id: str  # í•„ìˆ˜ë¡œ ë³€ê²½!
        context: Optional[Dict[str, Any]] = None
        
        class Config:
            json_schema_extra = {
                "example": {
                    "query": "ê°•ë‚¨ì—­ ê·¼ì²˜ ë§›ì§‘ ì¶”ì²œí•´ì¤˜",
                    "latitude": 37.5665,
                    "longitude": 126.9780,
                    "user_id": "user123"
                }
            }
    
    class RecommendResponse(BaseModel):
        """LLM ê¸°ë°˜ ì¶”ì²œ ì‘ë‹µ ëª¨ë¸"""
        success: bool
        query: str
        response: str
        mcp_results: Optional[Dict[str, Any]] = None
        error: Optional[str] = None


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
location_server = LocationServer()
llm_engine = LLMEngine()

# FastAPI ì•± ìƒì„±
if FASTAPI_AVAILABLE:
    app = FastAPI(
        title="ìœ„ì¹˜ ê¸°ë°˜ í• ì¸ ì„œë¹„ìŠ¤ API",
        description="Flutter ì•±ê³¼ MCP Serverë¥¼ ì—°ê²°í•˜ëŠ” REST API",
        version="1.0.0",
        # ë³´ì•ˆ: Swagger ë¬¸ì„œ ë¹„í™œì„±í™” (ì™¸ë¶€ ë…¸ì¶œ ë°©ì§€)
        docs_url=None,  # /docs ë¹„í™œì„±í™”
        redoc_url=None  # /redoc ë¹„í™œì„±í™”
    )
    
    # CORS ì„¤ì • (ëª¨ë°”ì¼ ì•± ì§€ì›)
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],  # ëª¨ë“  origin í—ˆìš© (ëª¨ë°”ì¼ 5G, WiFi ë“±)
        allow_credentials=True,
        allow_methods=["POST", "GET", "OPTIONS"],
        allow_headers=["Content-Type", "X-API-Key"],
    )
    
    # API í‚¤ ê²€ì¦ í•¨ìˆ˜ (ì£¼ìš” ë³´ì•ˆ ìˆ˜ë‹¨)
    async def verify_api_key(x_api_key: str = Header(None)):
        """API í‚¤ ê²€ì¦ (ë³´í˜¸ëœ ì—”ë“œí¬ì¸íŠ¸ìš©)"""
        if not x_api_key:
            raise HTTPException(
                status_code=401,
                detail="API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. Headerì— X-API-Keyë¥¼ í¬í•¨í•˜ì„¸ìš”."
            )
        
        if x_api_key != API_KEY:
            raise HTTPException(
                status_code=403,
                detail="ìœ íš¨í•˜ì§€ ì•Šì€ API í‚¤ì…ë‹ˆë‹¤"
            )
        return x_api_key
    
    @app.get("/")
    async def root():
        """API ë£¨íŠ¸ - ì„œë¹„ìŠ¤ ì •ë³´"""
        return {
            "service": "ìœ„ì¹˜ ê¸°ë°˜ í• ì¸ ì„œë¹„ìŠ¤ API",
            "status": "running",
            "version": "1.0.0",
            "message": "íŒ€ ì „ìš© API ì„œë²„ì…ë‹ˆë‹¤"
        }
    
    @app.get("/ping")
    async def ping():
        """
        ì´ˆê°„ë‹¨ ì—°ê²° í™•ì¸ (PowerShell pingê³¼ ìœ ì‚¬)
        
        íŒ€ì›ë“¤ì´ ê°€ì¥ ë¨¼ì € í…ŒìŠ¤íŠ¸í•´ì•¼ í•  ì—”ë“œí¬ì¸íŠ¸
        ìµœì†Œí•œì˜ ì‘ë‹µë§Œ ë°˜í™˜í•˜ì—¬ ë¹ ë¥´ê²Œ í™•ì¸
        """
        return {"pong": True}
    
    @app.get("/api/health")
    async def health_check():
        """ì„œë²„ ìƒíƒœ í™•ì¸ (ìƒì„¸ ì •ë³´)"""
        import platform
        import os
        
        return {
            "status": "healthy",
            "message": "ì„œë²„ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤",
            "details": {
                "python_version": platform.python_version(),
                "system": platform.system(),
                "node": platform.node(),
                "process_id": os.getpid()
            }
        }
    
    @app.get("/api/test")
    async def test_mcp_connection(api_key: str = Depends(verify_api_key)):
        """
        MCP ì„œë²„ í†µì‹  í…ŒìŠ¤íŠ¸ (API í‚¤ í•„ìš”)
        
        ì‹¤ì œë¡œ Location MCP Serverì™€ í†µì‹ í•˜ì—¬
        ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
        
        Header: X-API-Key: OSS_TEAM_SECRET_KEY_2025
        """
        try:
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤í–‰
            result = await location_server.search_stores(
                latitude=37.5665,
                longitude=126.9780,
                query="í…ŒìŠ¤íŠ¸"
            )
            
            if "error" in result:
                return {
                    "success": False,
                    "message": "MCP ì„œë²„ í†µì‹  ì‹¤íŒ¨",
                    "error": result["error"]
                }
            
            # ì„±ê³µ
            store_count = len(result.get("stores", []))
            return {
                "success": True,
                "message": "MCP ì„œë²„ í†µì‹  ì„±ê³µ",
                "test_result": {
                    "total_count": result.get("total_count", 0),
                    "returned_stores": store_count
                }
            }
            
        except Exception as e:
            return {
                "success": False,
                "message": "í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨",
                "error": str(e)
            }
    
    @app.post("/api/recommend", response_model=RecommendResponse)
    async def recommend_with_llm(
        request: RecommendRequest,
        api_key: str = Depends(verify_api_key)
    ):
        """
        LLM ê¸°ë°˜ ê°œì¸í™” ì¶”ì²œ API (API í‚¤ í•„ìš”)
        
        **ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ (2025-10-12 ì—…ë°ì´íŠ¸)**:
        1. Prompt Filter (ë„ë©”ì¸ ì œí•œ)
        2. PatternAnalysisServer (ì‚¬ìš©ì í”„ë¡œí•„ ë¡œë“œ) - í•­ìƒ í˜¸ì¶œ
        3. LocationServer (ì£¼ë³€ ìƒì  ê²€ìƒ‰) - í•­ìƒ í˜¸ì¶œ
        4. DiscountServer (í• ì¸ ì •ë³´ ë¶„ì„) - í•­ìƒ í˜¸ì¶œ
        5. RecommendationServer (í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ) - í•­ìƒ í˜¸ì¶œ
        6. RAG (ë²¡í„° ê²€ìƒ‰) - ìŠ¤í…
        7. OpenAI LLM (ìì—°ì–´ ì‘ë‹µ ìƒì„±)
        
        **í•„ìˆ˜ íŒŒë¼ë¯¸í„°**:
        - user_id: ì‚¬ìš©ì ID (ê°œì¸í™”ë¥¼ ìœ„í•´ í•„ìˆ˜!)
        - query: ìì—°ì–´ ì§ˆë¬¸
        - latitude, longitude: í˜„ì¬ ìœ„ì¹˜
        
        Header: X-API-Key: OSS_TEAM_SECRET_KEY_2025
        
        Args:
            request: ì¶”ì²œ ìš”ì²­ (ì§ˆë¬¸, ìœ„ë„, ê²½ë„, ì‚¬ìš©ìID ë“±)
        
        Returns:
            LLM ì‘ë‹µ
        
        Example:
            {
                "query": "ê°•ë‚¨ì—­ ê·¼ì²˜ ë§›ì§‘ ì¶”ì²œí•´ì¤˜. í• ì¸ ë§ì´ ë°›ì„ ìˆ˜ ìˆëŠ” ê³³ìœ¼ë¡œ",
                "latitude": 37.5665,
                "longitude": 126.9780,
                "user_id": "user123"
            }
        """
        try:
            result = await llm_engine.process_query(
                user_query=request.query,
                latitude=request.latitude,
                longitude=request.longitude,
                user_id=request.user_id,
                context=request.context
            )
            
            if not result["success"]:
                return RecommendResponse(
                    success=False,
                    query=request.query,
                    response=result["response"],
                    error=result.get("error")
                )
            
            return RecommendResponse(
                success=True,
                query=request.query,
                response=result["response"],
                mcp_results=result.get("mcp_results")
            )
            
        except Exception as e:
            raise HTTPException(
                status_code=500,
                detail=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}"
            )


# ============================================================
# í…ŒìŠ¤íŠ¸ ëª¨ë“œ
# ============================================================

async def test_mode():
    """í…ŒìŠ¤íŠ¸ ëª¨ë“œ - ê¸°ì¡´ ë™ì‘ ìœ ì§€"""
    client = LocationServer()
    
    print("ğŸŒŸ ìœ„ì¹˜ ê¸°ë°˜ í• ì¸ ì„œë¹„ìŠ¤ MCP Client (í…ŒìŠ¤íŠ¸ ëª¨ë“œ)")
    print("=" * 60)
    
    server_info = {
        "name": "Location Server (ìì²´ ê°œë°œ)",
        "type": "python",
        "path": "/opt/conda/envs/team/OSS/mcp-server/Discount_MAP_server/location_server.py",
        "description": "ìœ„ì¹˜ ê¸°ë°˜ ìƒì  ê²€ìƒ‰ ì„œë²„ (MVP í…ŒìŠ¤íŠ¸ìš©)"
    }
    
    print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ì„œë²„: {server_info['name']}")
    print(f"   ì„¤ëª…: {server_info['description']}")
    print(f"   ê²½ë¡œ: {server_info['path']}")
    
    server_params = StdioServerParameters(
        command="python",
        args=[server_info['path']],
        env={"PYTHONPATH": "/opt/conda/envs/team/lib/python3.11/site-packages"}
    )
    
    await client.test_connection(server_params)
    
    print("\n" + "=" * 60)
    print("ğŸ’¡ ì°¸ê³ :")
    print("   - API ì„œë²„ ëª¨ë“œ: python mcp_client.py --mode api")
    print("   - í…ŒìŠ¤íŠ¸ ëª¨ë“œ: python mcp_client.py --mode test")
    print("=" * 60)


# ============================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================

def main():
    """ë©”ì¸ ì§„ì…ì """
    parser = argparse.ArgumentParser(description="ìœ„ì¹˜ ê¸°ë°˜ í• ì¸ ì„œë¹„ìŠ¤ MCP Client")
    parser.add_argument(
        "--mode",
        choices=["api", "test"],
        default="test",
        help="ì‹¤í–‰ ëª¨ë“œ: api (REST API ì„œë²„) ë˜ëŠ” test (í…ŒìŠ¤íŠ¸)"
    )
    parser.add_argument(
        "--host",
        default="0.0.0.0",
        help="API ì„œë²„ í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸: 0.0.0.0)"
    )
    parser.add_argument(
        "--port",
        type=int,
        default=8000,
        help="API ì„œë²„ í¬íŠ¸ (ê¸°ë³¸: 8000)"
    )
    
    args = parser.parse_args()
    
    if args.mode == "api":
        if not FASTAPI_AVAILABLE:
            print("âŒ FastAPIê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   ì‹¤í–‰: pip install fastapi uvicorn pydantic")
            sys.exit(1)
        
        # ì‹¤ì œ ì„œë²„ IP ìë™ ê°ì§€
        import socket
        try:
            hostname = socket.gethostname()
            local_ip = socket.gethostbyname(hostname)
        except:
            local_ip = "ì„œë²„IPí™•ì¸í•„ìš”"
        
        print("ğŸš€ REST API ì„œë²„ ì‹œì‘...")
        print(f"   ë°”ì¸ë“œ ì£¼ì†Œ: {args.host}:{args.port}")
        print(f"\nğŸ“± Flutter ì•± ì ‘ì† ì£¼ì†Œ:")
        print(f"   â–¶ http://{local_ip}:{args.port}/api/recommend")
        print(f"\nğŸ”§ ê°œë°œì í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸:")
        print(f"   â–¶ GET  http://localhost:{args.port}/ping")
        print(f"   â–¶ GET  http://localhost:{args.port}/api/health")
        print(f"   â–¶ GET  http://localhost:{args.port}/api/test")
        print(f"\nğŸ’¡ ì°¸ê³ :")
        print(f"   - Flutter ì•±ì€ /api/recommend ì—”ë“œí¬ì¸íŠ¸ë§Œ ì‚¬ìš©")
        print(f"   - user_idëŠ” í•„ìˆ˜ íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤")
        print(f"   - API ë¬¸ì„œ(Swagger)ëŠ” ë³´ì•ˆìƒ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
        print("\n" + "=" * 60)
        
        uvicorn.run(app, host=args.host, port=args.port)
    
    else:  # test ëª¨ë“œ
        asyncio.run(test_mode())


if __name__ == "__main__":
    main()


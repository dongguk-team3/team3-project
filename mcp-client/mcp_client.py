"""
MCP Client MVP - ìœ„ì¹˜ ê¸°ë°˜ í• ì¸ ì„œë¹„ìŠ¤
REST API ì„œë²„ + MCP Client + LLM í†µí•©

ì‹¤í–‰ ëª¨ë“œ:
1. API ì„œë²„ ëª¨ë“œ: python mcp_client.py --mode api

"""

import asyncio
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from typing import Optional, Dict, Any, List
import json
import sys
import os
import argparse

# RAG í†µí•©
from RAG.rag_module import RAGPipeline
from chat_filter_pipeline import ChatFilterPipeline


# FastAPI ê´€ë ¨ (API ëª¨ë“œì—ì„œë§Œ ì‚¬ìš©)
try:
    from fastapi import FastAPI, HTTPException, Depends, Header, Request
    from fastapi.middleware.cors import CORSMiddleware
    from fastapi.staticfiles import StaticFiles
    from fastapi.responses import FileResponse, HTMLResponse
    from pydantic import BaseModel
    from fastapi.security import APIKeyHeader
    import uvicorn
    import json
    FASTAPI_AVAILABLE = True
except ImportError:
    FASTAPI_AVAILABLE = False
    print("âš ï¸  FastAPIê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install fastapi uvicorn' ì‹¤í–‰")

# OpenAI í†µí•©
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    OpenAI = None
    print("âš ï¸  OpenAIê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LLM ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install openai' ì‹¤í–‰")


# API í‚¤ (íŒ€ì›ë“¤ê³¼ ê³µìœ í•  ë¹„ë°€ í‚¤)
API_KEY = os.getenv("API_KEY", "OSS_TEAM_SECRET_KEY_2025")

# ì ‘ê·¼ ì œì–´ ì„¤ì • ë¡œë“œ
def load_access_config():
    """config.jsonì—ì„œ ì ‘ê·¼ ì œì–´ ì„¤ì • ë¡œë“œ"""
    config_path = os.path.join(os.path.dirname(__file__), "config.json")
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            return config
    except FileNotFoundError:
        # ê¸°ë³¸ ì„¤ì •
        return {
            "allowed_ips": ["127.0.0.1", "localhost", "::1"],
            "allowed_ports": [8000, 8001, 8002, 8080, 3000, 5000],
            "developer_mode": True,
            "enable_ip_whitelist": False,
            "enable_port_whitelist": False,
            "default_host": "0.0.0.0",
            "default_port": 8000
        }
    except Exception as e:
        print(f"âš ï¸  ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {
            "allowed_ips": ["127.0.0.1", "localhost", "::1"],
            "allowed_ports": [8000, 8001, 8002, 8080, 3000, 5000],
            "developer_mode": True,
            "enable_ip_whitelist": False,
            "enable_port_whitelist": False,
            "default_host": "0.0.0.0",
            "default_port": 8000
        }

ACCESS_CONFIG = load_access_config()

# OpenAI API í‚¤ ë¡œë“œ
def load_openai_api_key():
    """OPENAI_API.txt íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ"""
    try:
        key_file = os.path.join(os.path.dirname(__file__), "OPENAI_API.txt")
        with open(key_file, 'r') as f:
            key = f.read().strip()
            if key and key != "YOUR_API_KEY_HERE":
                return key
    except FileNotFoundError:
        pass
    
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì‹œë„
    return os.getenv("OPENAI_API_KEY", None)

# OpenAI API ì„¤ì •
OPENAI_API_KEY = load_openai_api_key()
OPENAI_CLIENT = None

if OPENAI_API_KEY and OPENAI_AVAILABLE:
    try:
        OPENAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY)
        print(f"âœ… OpenAI API í‚¤ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸  OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
else:
    print(f"âš ï¸  OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")




# ==================== MCP Server í´ë˜ìŠ¤ë“¤ ====================

class LocationServer:
    """ìœ„ì¹˜ ê¸°ë°˜ ìƒì  ê²€ìƒ‰ ì„œë²„"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.server_path = "ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë°”ê¿€ ê²ƒ."
        # ì˜ˆì‹œ: self.server_path = "/opt/conda/envs/team/OSS/mcp-server/Location_server/location_server.py" ## ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë°”ê¿€ ê²ƒ.
    
    # async def search_stores(self, latitude: float, longitude: float, query: str) -> Dict[str, Any]:
    #     """
    #     ìƒì  ê²€ìƒ‰ (MCP Server í˜¸ì¶œ)
        
    #     Args:
    #         latitude: ìœ„ë„
    #         longitude: ê²½ë„
    #         query: ê²€ìƒ‰ ì¿¼ë¦¬ (ì˜ˆ: "ìŒì‹ì ", "ì¹´í˜")
        
    #     Returns:
    #         ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    #     """
    #     server_params = StdioServerParameters(
    #         command="python",
    #         args=[self.server_path],
    #         env={"PYTHONPATH": "/opt/conda/envs/team/lib/python3.11/site-packages"}
    #     )
        
    #     try:
    #         async with stdio_client(server_params) as (read, write):
    #             async with ClientSession(read, write) as session:
    #                 await session.initialize()
                    
    #                 # search_nearby_stores ë„êµ¬ í˜¸ì¶œ
    #                 result = await session.call_tool(
    #                     "search_nearby_stores",
    #                     {
    #                         "latitude": latitude,
    #                         "longitude": longitude,
    #                         "category": query
    #                     }
    #                 )
                    
    #                 # ê²°ê³¼ íŒŒì‹±
    #                 if result.content and len(result.content) > 0:
    #                     response_text = result.content[0].text if hasattr(result.content[0], 'text') else str(result.content[0])
    #                     parsed_result = json.loads(response_text)
    #                     print(f"   MCP ì„œë²„ ì‘ë‹µ: {parsed_result.get('message', 'N/A')}")
    #                     print(f"   ê°€ê²Œ ìˆ˜: {len(parsed_result.get('stores', []))}ê°œ")
    #                     return parsed_result
                    
    #                 print("   âš ï¸ MCP ì„œë²„ì—ì„œ ë¹ˆ ì‘ë‹µ ë°›ìŒ")
    #                 return {"stores": [], "error": "ê²°ê³¼ ì—†ìŒ"}
                    
    #     except Exception as e:
    #         print(f"   âŒ MCP í†µì‹  ì˜¤ë¥˜: {e}")
    #         return {
    #             "stores": [],
    #             "error": f"MCP ì„œë²„ í†µì‹  ì˜¤ë¥˜: {str(e)}",
    #             "details": str(e)
    #         }
    
    # ## ë””ë²„ê¹…ìš© í•¨ìˆ˜
    # async def test_connection(self, server_params: StdioServerParameters):
    #     """MCP ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    #     print("=" * 60)
    #     print("ğŸš€ MCP Client MVP í…ŒìŠ¤íŠ¸ ì‹œì‘")
    #     print("=" * 60)
        
    #     try:
    #         print(f"ğŸ”Œ MCP ì„œë²„ì— ì—°ê²° ì¤‘...")
            
    #         # stdio_clientë¡œ ì„œë²„ì™€ ì—°ê²°
    #         async with stdio_client(server_params) as (read, write):
    #             async with ClientSession(read, write) as session:
    #                 # ì„¸ì…˜ ì´ˆê¸°í™”
    #                 init_result = await session.initialize()
    #                 print(f"âœ… MCP ì„œë²„ ì—°ê²° ì„±ê³µ!")
                    
    #                 # ì„œë²„ ì •ë³´ ì¶œë ¥
    #                 print(f"\nğŸ“‹ ì„œë²„ ì •ë³´:")
    #                 print(f"  - ì„œë²„ ì´ë¦„: {init_result.serverInfo.name}")
    #                 print(f"  - í”„ë¡œí† ì½œ ë²„ì „: {init_result.protocolVersion}")
                    
    #                 # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ì¡°íšŒ
    #                 print(f"\nğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡:")
    #                 tools_list = await session.list_tools()
                    
    #                 if not tools_list.tools:
    #                     print("  ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    #                     return
                    
    #                 for i, tool in enumerate(tools_list.tools, 1):
    #                     print(f"  {i}. {tool.name}")
    #                     if hasattr(tool, 'description') and tool.description:
    #                         print(f"     ì„¤ëª…: {tool.description}")
    #                     if hasattr(tool, 'inputSchema'):
    #                         print(f"     íŒŒë¼ë¯¸í„°: {tool.inputSchema}")
                    
    #                 # ì²« ë²ˆì§¸ ë„êµ¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    #                 if tools_list.tools:
    #                     first_tool = tools_list.tools[0]
    #                     print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ë„êµ¬ ì‹¤í–‰: {first_tool.name}")
                        
    #                     # ë„êµ¬ì— ë”°ë¼ ì ì ˆí•œ íŒŒë¼ë¯¸í„° ì„¤ì •
    #                     test_args = self._get_test_arguments(first_tool.name)
                        
    #                     if test_args is not None:
    #                         print(f"   íŒŒë¼ë¯¸í„°: {json.dumps(test_args, ensure_ascii=False, indent=2)}")
                            
    #                         try:
    #                             result = await session.call_tool(first_tool.name, test_args)
    #                             print(f"âœ… ë„êµ¬ ì‹¤í–‰ ì„±ê³µ!")
    #                             print(f"   ê²°ê³¼:")
    #                             for content in result.content:
    #                                 if hasattr(content, 'text'):
    #                                     print(f"   {content.text}")
    #                                 else:
    #                                     print(f"   {content}")
    #                         except Exception as e:
    #                             print(f"âš ï¸  ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    #                     else:
    #                         print(f"   (ì´ ë„êµ¬ëŠ” í•„ìˆ˜ íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•˜ì—¬ ìŠ¤í‚µí•©ë‹ˆë‹¤)")
                    
    #                 print("\n" + "=" * 60)
    #                 print("âœ… MCP Client MVP í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    #                 print("=" * 60)
            
    #     except Exception as e:
    #         print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    #         import traceback
    #         traceback.print_exc()
    
    # ## ë””ë²„ê¹…ìš© í•¨ìˆ˜
    # def _get_test_arguments(self, tool_name: str) -> Optional[dict]:
    #     """ë„êµ¬ë³„ í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„° ë°˜í™˜"""
    #     # ìì²´ ìœ„ì¹˜ ì„œë²„ ë„êµ¬ë“¤
    #     if tool_name == "search_nearby_stores":
    #         return {
    #             "latitude": 37.5665,   # ì„œìš¸ ì‹œì²­ ìœ„ë„
    #             "longitude": 126.9780, # ì„œìš¸ ì‹œì²­ ê²½ë„
    #             "category": "ìŒì‹ì "
    #         }
        
    #     if tool_name == "get_store_info":
    #         return {
    #             "store_id": "store_001"
    #         }
        
    #     # ê¸°ë³¸ì ìœ¼ë¡œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
    #     return {}


class DiscountServer:
    """í• ì¸ ì •ë³´ ìˆ˜ì§‘ ì„œë²„ (ì¶”í›„ êµ¬í˜„ ì˜ˆì •)"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        # TODO: ì‹¤ì œ í• ì¸ ì •ë³´ MCP ì„œë²„ ê²½ë¡œ ì„¤ì •
        self.server_path = "ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë°”ê¿€ ê²ƒ."
        # ì˜ˆì‹œ: self.server_path = "/opt/conda/envs/team/OSS/mcp-server/Discount_MAP_server/discount_server.py"
        self.is_implemented = False
    
    # async def get_discounts(
    #     self, 
    #     stores: List[Dict], 
    #     user_profile: Dict[str, Any]
    # ) -> Dict[str, Any]:
    #     """
    #     ì—¬ëŸ¬ ê°€ê²Œì˜ í• ì¸ ì •ë³´ ì¼ê´„ ì¡°íšŒ (ì‚¬ìš©ì í”„ë¡œí•„ ê¸°ë°˜)
        
    #     Args:
    #         stores: ê°€ê²Œ ëª©ë¡ (LocationServer ê²°ê³¼)
    #         user_profile: ì‚¬ìš©ì í”„ë¡œí•„ (PatternAnalysisServer ê²°ê³¼)
    #             - telecom: í†µì‹ ì‚¬
    #             - cards: ë³´ìœ  ì¹´ë“œ ëª©ë¡
    #             - memberships: ë©¤ë²„ì‹­ ëª©ë¡
        
    #     Returns:
    #         ê°€ê²Œë³„ í• ì¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    #     """
    #     if not self.is_implemented:
    #         # TODO: ì‹¤ì œ MCP ì„œë²„ êµ¬í˜„ í›„ ì œê±°
    #         # Mock ë°ì´í„°: ê° ê°€ê²Œë³„ í• ì¸ ì •ë³´ ìƒì„±
    #         discounts_by_store = {}
            
    #         for store in stores[:5]:  # ìƒìœ„ 5ê°œë§Œ Mock
    #             store_id = store.get("id", "unknown")
    #             store_name = store.get("name", "ì•Œ ìˆ˜ ì—†ìŒ")
                
    #             # Mock í• ì¸ ìƒì„±
    #             mock_discounts = []
                
    #             # í†µì‹ ì‚¬ í• ì¸ (Mock)
    #             telecom = user_profile.get("telecom", "")
    #             if telecom in ["SKT", "KT", "LG U+"]:
    #                 mock_discounts.append({
    #                     "type": "telecom",
    #                     "provider": telecom,
    #                     "rate": 20,
    #                     "description": f"{telecom} í†µì‹ ì‚¬ ì œíœ´ 20% í• ì¸"
    #                 })
                
    #             # ì¹´ë“œ í• ì¸ (Mock)
    #             cards = user_profile.get("cards", {})
    #             primary_card = cards.get("primary", "")
    #             if primary_card:
    #                 mock_discounts.append({
    #                     "type": "card",
    #                     "provider": primary_card,
    #                     "rate": 10,
    #                     "description": f"{primary_card} 10% ì¦‰ì‹œí• ì¸"
    #                 })
                
    #             # ìµœëŒ€ í• ì¸ìœ¨ ê³„ì‚°
    #             max_discount = max([d["rate"] for d in mock_discounts], default=0)
                
    #             discounts_by_store[store_id] = {
    #                 "store_id": store_id,
    #                 "store_name": store_name,
    #                 "discounts": mock_discounts,
    #                 "max_discount": max_discount,
    #                 "best_payment": mock_discounts[0] if mock_discounts else None
    #             }
            
    #         return {
    #             "message": "âš ï¸ í• ì¸ ì •ë³´ ì„œë²„ëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (Mock ë°ì´í„°).",
    #             "discounts_by_store": discounts_by_store,
    #             "total_stores_analyzed": len(discounts_by_store)
    #         }
        
    #     # TODO: ì‹¤ì œ MCP ì„œë²„ í˜¸ì¶œ ë¡œì§ êµ¬í˜„
    #     pass


class RecommendationServer:
    """ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì„œë²„ (ì¶”í›„ êµ¬í˜„ ì˜ˆì •)"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        # TODO: ì‹¤ì œ ì¶”ì²œ MCP ì„œë²„ ê²½ë¡œ ì„¤ì •
        self.server_path = "ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë°”ê¿€ ê²ƒ."
        # ì˜ˆì‹œ: self.server_path = "/opt/conda/envs/team/OSS/mcp-server/Recommendation_server/recommendation_server.py"
        self.is_implemented = False
    
    # async def get_recommendations(
    #     self, 
    #     user_id: str,
    #     user_profile: Dict[str, Any],
    #     user_preferences: Dict[str, Any],
    #     stores: List[Dict],
    #     discounts: Dict[str, Any],
    #     context: Dict = None
    # ) -> Dict[str, Any]:
    #     """
    #     ì‚¬ìš©ì ë§ì¶¤ ì¶”ì²œ ìƒì„± (ëª¨ë“  MCP Server ê²°ê³¼ ì¢…í•©)
        
    #     Args:
    #         user_id: ì‚¬ìš©ì ID
    #         user_profile: ì‚¬ìš©ì í”„ë¡œí•„ (í†µì‹ ì‚¬, ì¹´ë“œ ë“±)
    #         user_preferences: ì‚¬ìš©ì ì„ í˜¸ë„ (ì„ í˜¸ ì¹´í…Œê³ ë¦¬, í‰ê·  ì˜ˆì‚° ë“±)
    #         stores: ìƒì  ëª©ë¡ (LocationServer)
    #         discounts: í• ì¸ ì •ë³´ (DiscountServer)
    #         context: ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (ì‹œê°„, ë‚ ì”¨ ë“±)
        
    #     Returns:
    #         ì¶”ì²œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (ìˆœìœ„ë³„ ì ìˆ˜ í¬í•¨)
    #     """
    #     if not self.is_implemented:
    #         # TODO: ì‹¤ì œ MCP ì„œë²„ êµ¬í˜„ í›„ ì œê±°
    #         # Mock: í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì‹œë®¬ë ˆì´ì…˜
            
    #         discounts_data = discounts.get("discounts_by_store", {})
    #         preferred_categories = user_preferences.get("preferred_categories", [])
    #         avg_budget = user_preferences.get("avg_budget", 15000)
            
    #         scored_stores = []
            
    #         for store in stores:
    #             store_id = store.get("id", "")
    #             store_name = store.get("name", "ì•Œ ìˆ˜ ì—†ìŒ")
    #             category = store.get("category_name", "")
    #             distance = store.get("distance", 999999)
                
    #             # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° (Mock)
    #             score = 0.0
    #             breakdown = {}
                
    #             # [1] Content-Based Filtering (40%)
    #             content_score = 0.0
    #             # A. ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ (25ì )
    #             if any(cat in category for cat in preferred_categories):
    #                 content_score += 0.25
    #             # B. ê±°ë¦¬ ì ìˆ˜ (15ì ) - ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ìŒ
    #             distance_score = max(0, 1 - (distance / 1000)) * 0.15
    #             content_score += distance_score
                
    #             breakdown["content_based"] = content_score * 0.4
    #             score += content_score * 0.4
                
    #             # [2] Collaborative Filtering (30%) - Mock: ëœë¤
    #             collab_score = 0.15  # Mock: í‰ê·  ì ìˆ˜
    #             breakdown["collaborative"] = collab_score * 0.3
    #             score += collab_score * 0.3
                
    #             # [3] Discount Optimization (30%)
    #             discount_info = discounts_data.get(store_id, {})
    #             max_discount = discount_info.get("max_discount", 0)
    #             discount_score = min(max_discount / 30, 1.0) * 0.3
    #             breakdown["discount"] = discount_score
    #             score += discount_score
                
    #             # ì¶”ì²œ ì´ìœ  ìƒì„±
    #             reasons = []
    #             if any(cat in category for cat in preferred_categories):
    #                 reasons.append(f"ì„ í˜¸í•˜ì‹œëŠ” {category} ì¹´í…Œê³ ë¦¬")
    #             if max_discount > 0:
    #                 best_payment = discount_info.get("best_payment", {})
    #                 provider = best_payment.get("provider", "") if best_payment else ""
    #                 reasons.append(f"{provider} {max_discount}% í• ì¸")
    #             if distance < 300:
    #                 reasons.append(f"ê°€ê¹Œìš´ ê±°ë¦¬ ({distance}m)")
                
    #             scored_stores.append({
    #                 "rank": 0,  # ë‚˜ì¤‘ì— ì •ë ¬ í›„ ì„¤ì •
    #                 "store": store,
    #                 "score": round(score, 2),
    #                 "score_breakdown": breakdown,
    #                 "discount_info": discount_info,
    #                 "recommendation_reason": ", ".join(reasons) if reasons else "ì£¼ë³€ ì¸ê¸° ë§¤ì¥"
    #             })
            
    #         # ì ìˆ˜ìˆœ ì •ë ¬
    #         scored_stores.sort(key=lambda x: x["score"], reverse=True)
            
    #         # ìˆœìœ„ ë¶€ì—¬
    #         for idx, item in enumerate(scored_stores, 1):
    #             item["rank"] = idx
            
    #         return {
    #             "message": "âš ï¸ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì„œë²„ëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (Mock ì•Œê³ ë¦¬ì¦˜).",
    #             "recommendations": scored_stores[:10],
    #             "total_candidates": len(stores),
    #             "algorithm": "HybridRecommender (Mock)",
    #             "weights": {
    #                 "content_based": 0.4,
    #                 "collaborative": 0.3,
    #                 "discount": 0.3
    #             }
    #         }
        
    #     # TODO: ì‹¤ì œ MCP ì„œë²„ í˜¸ì¶œ ë¡œì§ êµ¬í˜„
    #     pass




# ============================================================
# LLM í†µí•© ë ˆì´ì–´
# ============================================================

class LLMEngine:
    """LLM ì—”ì§„ (OpenAI + RAG)"""
    
    def __init__(self):
        """
        ì´ˆê¸°í™”
        """
        self.chat_filter_pipeline = ChatFilterPipeline()  # chat.py í†µí•©
        self.rag_pipeline = RAGPipeline(use_openai_embeddings=False)
        self.location_server = LocationServer()
        self.discount_server = DiscountServer()
        self.recommendation_server = RecommendationServer()
        
        # OpenAI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        self.openai_available = OPENAI_AVAILABLE and OPENAI_API_KEY and OPENAI_CLIENT
        self.openai_client = OPENAI_CLIENT
    
    async def process_query(
        self,
        user_query: str,
        latitude: float,
        longitude: float,
        user_id: str,  # í•„ìˆ˜ë¡œ ë³€ê²½!
        user_profile: Dict[str, Any] = None,
        mode: List[int] = None,
    ) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬ (ìˆ˜ì •ëœ ì•„í‚¤í…ì²˜)
        
        ì•„í‚¤í…ì²˜ íë¦„:
        1. Prompt Filter
        2. LocationServer
        3. DiscountServer 
        4. RecommendationServer 
        5. RAG
        6. OpenAI LLM
        
        Args:
            user_query: ì‚¬ìš©ì ì§ˆë¬¸
            latitude: ìœ„ë„
            longitude: ê²½ë„
            user_id: ì‚¬ìš©ì ID (í•„ìˆ˜!)
        
        Returns:
            LLM ì‘ë‹µ
        """
        print("\n" + "="*60)
        print(f"ğŸ¯ LLM ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘")
        print(f"   ì‚¬ìš©ì: {user_id}")
        print(f"   ì§ˆë¬¸: {user_query}")
        print(f"   ìœ„ì¹˜: ({latitude}, {longitude})")
        print("="*60)
        
        if mode is None:
            print(" ì²˜ë¦¬ ëª¨ë“œ ì§€ì • í•„ìš”.")
            return {
                "success": False,
                "response": "modeê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "mcp_results": {},
                "error": "MODE_NOT_SPECIFIED",
            }        
        ################################################ 1. Prompt Filtering ë„ë©”ì¸ ì œí•œ ë° ì§€ë„ ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ
        
        print(f"\n[1/6] ğŸ›¡ï¸  ChatFilterPipeline ì‹¤í–‰ ì¤‘...")
        
        # User Profile ìƒì„± (user_id ê¸°ë°˜ ê¸°ë³¸ê°’)
        base_user_profile = {
            "userId": user_id,
            "telco": "SKT",  # TODO: ì‹¤ì œ ì‚¬ìš©ì ë°ì´í„°ë¡œ ëŒ€ì²´
            "memberships": [],
            "cards": [],
            "affiliations": []
        }
        # ì™¸ë¶€ì—ì„œ ì „ë‹¬ëœ user_profileì´ ìˆìœ¼ë©´ ê¸°ë³¸ê°’ê³¼ ë³‘í•©
        if user_profile:
            provided_profile = {
                key: value for key, value in user_profile.items()
                if value is not None
            }
            base_user_profile.update(provided_profile)
        # ì„œë²„ê°€ ë°›ì€ user_idë¥¼ ê°•ì œ ì£¼ì…í•´ ì¼ê´€ì„± ìœ ì§€
        base_user_profile["userId"] = user_id
        user_profile = base_user_profile
        
        ################################## MCP ê²°ê³¼ë¥¼ ë‹¨ê³„ë³„ë¡œ ëˆ„ì í•˜ì—¬ RAG ë° LLM ë‹¨ê³„ì—ì„œ ì¬ì‚¬ìš©
        mcp_results: Dict[str, Any] = {
            "user_query": user_query,
            "user_profile": user_profile,
        }
        
        # ChatFilterPipeline ì‹¤í–‰
        filter_result = self.chat_filter_pipeline.process(
            user_query=user_query,
            user_profile=user_profile
        )
        
        if not filter_result["success"]:
            print(f"âŒ ChatFilterPipeline ê±°ë¶€: {filter_result['message']}")
            return {
                "success": False,
                "error": filter_result.get("error", "validation_failed"),
                "response": filter_result["message"],
                "mcp_results": {}
            }
        
        print(f"âœ… ChatFilterPipeline í†µê³¼")
        print(f"   í‚¤ì›Œë“œ: {filter_result['keywords']}")
        print(f"   MCP Ready: {filter_result['mcp_ready']}")
        
        # ê²°ê³¼ ì €ì¥
        keywords = filter_result["keywords"]
        extracted_user_profile = filter_result["user_profile"]
        
        # mode[0] and not mode[1]: Prompt Filterê¹Œì§€ë§Œ ì‹¤í–‰
        if mode[0] and not mode[1]:
            return {
                "success": True,
                "response": "ChatFilterPipeline ì™„ë£Œ",
                "keywords": keywords,
                "user_profile": extracted_user_profile,
                "mcp_ready": filter_result["mcp_ready"],
                "mcp_results": {
                    "step": "chat_filter_pipeline",
                    "keywords": keywords,
                    "user_profile": extracted_user_profile
                },
                "error": None,
            }
        
        # ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ë‹¬í•  ë³€ìˆ˜ë“¤
        place_type = keywords.get("place_type")
        location = keywords.get("location")
        attributes = keywords.get("attributes", [])
        ## extracted_user_profileë¥¼ í• ì¸ dbì—ì„œ ì‚¬ìš©í•˜ë©´ ë¨.
        user_profile = extracted_user_profile
        
        
        
        ################################################ 2. LocationServer
        print(f"\n[2/6] ğŸ“ LocationServer í˜¸ì¶œ ì¤‘...")
        if mode[1] and not mode[2]:
            
            ## locationê³¼ query_keywordsëŠ” Prompt Filter ê²°ê³¼ì—ì„œ ì¶”ì¶œëœ ê²ƒì„ ì‚¬ìš©.
            ## ê°€ê²Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ì„œ ë°˜í™˜.    
            
            ### not mode[2] ì´ë¼ëŠ” ì†Œë¦¬ëŠ” Discount serverê¹Œì§€ì˜ ë„˜ì–´ê°ˆ í•„ìš”ê°€ ì—†ë‹¤ëŠ” ê²ƒì´ë¯€ë¡œ ì—¬ê¸°ì„œ ì¢…ë£Œ.
            return 
        else:
            pass
            ## ìœ„ì™€ ê°™ì€ êµ¬í˜„ì„ í•  ê±´ë° ë‹¤ìŒ ëª¨ë“œë¡œ ë„˜ì–´ê°ˆ ê²°ê³¼ê°’ì„ êµ¬í˜„í•˜ë©´ ë¨.
        
        ## output
        ## stores: ê°€ê²Œ ë¦¬ìŠ¤íŠ¸
        ## reviews: ê°€ê²Œ ë¦¬ë·° ë¦¬ìŠ¤íŠ¸ (ì¶”í›„ RAGìš©)
        mcp_results["location_server"] = {
            "stores": stores,
            "reviews": reviews
        }
        
       
        
        
        # 3. DiscountServer (LocationServer ê²°ê³¼ + ì‚¬ìš©ì í”„ë¡œí•„ ì‚¬ìš©)
        print(f"\n[3/6] ğŸ’° DiscountServer í˜¸ì¶œ ì¤‘...")
        if mode[2] and not mode[3]:
            
            discount_result = await self.discount_server.get_discounts(
                stores=stores,
                user_profile=user_profile
            )
        
            ### not mode[3] ì´ë¼ëŠ” ì†Œë¦¬ëŠ” Recommendation serverê¹Œì§€ì˜ ë„˜ì–´ê°ˆ í•„ìš”ê°€ ì—†ë‹¤ëŠ” ê²ƒì´ë¯€ë¡œ ì—¬ê¸°ì„œ ì¢…ë£Œ.
            return 
        else:
            pass
            ## ìœ„ì™€ ê°™ì€ êµ¬í˜„ì„ í•  ê±´ë° ë‹¤ìŒ ëª¨ë“œë¡œ ë„˜ì–´ê°ˆ ê²°ê³¼ê°’ì„ êµ¬í˜„í•˜ë©´ ë¨.
            
        ## output
        ## discounts_by_store: ê°€ê²Œë³„ í• ì¸ ì •ë³´
        
        
        
        # 4. RecommendationServer (í• ì¸ìœ¨ ìˆœ, ê±°ë¦¬ ìˆœ ë“± ì •ë ¬ ê²°ê³¼ ë§Œë“¤ê¸°)
        print(f"\n[4/6] ğŸ¯ RecommendationServer í˜¸ì¶œ ì¤‘...")
        if mode[3] and not mode[4]:
            recommendation_result = await self.recommendation_server.get_recommendations(
                user_id=user_id,
                stores=stores,
                discounts=discounts_by_store,
            )

            
            ### not mode[4] ì´ë¼ëŠ” ì†Œë¦¬ëŠ” RAGê¹Œì§€ì˜ ë„˜ì–´ê°ˆ í•„ìš”ê°€ ì—†ë‹¤ëŠ” ê²ƒì´ë¯€ë¡œ ì—¬ê¸°ì„œ ì¢…ë£Œ.
            return 
        else:
            pass
            ## ìœ„ì™€ ê°™ì€ êµ¬í˜„ì„ í•  ê±´ë° ë‹¤ìŒ ëª¨ë“œë¡œ ë„˜ì–´ê°ˆ ê²°ê³¼ê°’ì„ êµ¬í˜„í•˜ë©´ ë¨.
        
        ### output
        ### recommendations: ì¶”ì²œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (í• ì¸ìœ¨ ìˆœ, ê±°ë¦¬ìˆœ)
        mcp_results["recommendation_server"] = {
            "recommendations": recommendation_result
        }
        
        
        ####### ì•„ë˜ëŠ” RAGìš© ì´ë‹ˆê¹Œ ì‹ ê²½ X ##########
        # RAG (ë²¡í„° DB ìƒì„± ë° ê²€ìƒ‰) - ìŠ¤í…
        if mode[4]:
            print(f"\n[6/6] ğŸ” RAG ì²˜ë¦¬ ì¤‘...")
            rag_result = self.rag_pipeline.process(
                user_query=user_query,
                mcp_results=mcp_results,
                top_k=3,
                session_id=user_id,
                user_profile=user_profile
            )
            print(f"âœ… RAG ì²˜ë¦¬ ì™„ë£Œ (ìŠ¤í… ëª¨ë“œ)")
            
            # [4ë‹¨ê³„] OpenAI LLM í˜¸ì¶œ (ì‹¤ì œ êµ¬í˜„)
            print(f"\nğŸ¤– OpenAI LLM í˜¸ì¶œ ì¤‘...")
            if self.openai_available:
                response = await self._call_openai_llm(
                    user_query=user_query,
                    llm_context=rag_result["llm_context"],
                    filter_result=filter_result,
                    user_profile=user_profile
                )
                print(f"âœ… LLM ì‘ë‹µ ìƒì„± ì™„ë£Œ")
            else:
                response = rag_result.get("fallback_answer", "LLM ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            print("\n" + "="*60)
            print(f"âœ… ì¿¼ë¦¬ ì²˜ë¦¬ ì™„ë£Œ")
            print("="*60 + "\n")
            
            return {
                "success": True,
                "query": user_query,
                "response": response,
                "mcp_results": mcp_results,
                "rag_result": rag_result
            }
        
    
    async def _call_openai_llm(
        self,
        user_query: str,
        llm_context: str,
        filter_result: Optional[Dict[str, Any]],
        user_profile: Dict[str, Any]
    ) -> str:
        """
        OpenAI LLM í˜¸ì¶œ (OpenAI ê³µì‹ ë¬¸ì„œ ê¸°ì¤€)
        
        Args:
            user_query: ì‚¬ìš©ì ì§ˆë¬¸
            llm_context: RAGë¡œ ìƒì„±ëœ ì»¨í…ìŠ¤íŠ¸
            filter_result: Prompt Filter ê²°ê³¼
        
        Returns:
            LLM ìƒì„± ì‘ë‹µ
        """
        try:
            keywords = filter_result.get("keywords") if filter_result else None
            keyword_text = ""
            if keywords:
                place = keywords.get("place_type")
                attributes = ", ".join(keywords.get("attributes", []))
                location = keywords.get("location")
                keyword_text = f"í‚¤ì›Œë“œ: ì¥ì†Œ={place}, ì†ì„±={attributes}, ì§€ì—­={location}"
            
            profile_desc = []
            telco = user_profile.get("telco")
            cards = ", ".join(user_profile.get("cards", []))
            memberships = ", ".join(user_profile.get("memberships", []))
            if telco:
                profile_desc.append(f"í†µì‹ ì‚¬ {telco}")
            if cards:
                profile_desc.append(f"ì¹´ë“œ {cards}")
            if memberships:
                profile_desc.append(f"ë©¤ë²„ì‹­ {memberships}")
            profile_text = ", ".join(profile_desc)
            
            system_message = (
                "ë‹¹ì‹ ì€ ìœ„ì¹˜ ê¸°ë°˜ ë§›ì§‘/ì¹´í˜ ì¶”ì²œ ë¹„ì„œì…ë‹ˆë‹¤. "
                "ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ë°›ì„ ìˆ˜ ìˆëŠ” í• ì¸ í˜œíƒê³¼ ë¦¬ë·° ë¶„ìœ„ê¸°ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì•ˆë‚´í•˜ì„¸ìš”. "
                "ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ ë°–ì˜ ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”."
            )
            if profile_text:
                system_message += f" ì‚¬ìš©ì í”„ë¡œí•„: {profile_text}."
            if keyword_text:
                system_message += f" {keyword_text}."
            
            messages = [
                {"role": "system", "content": system_message},
                {
                    "role": "system",
                    "content": f"""[ê²€ìƒ‰ëœ ì •ë³´]
{llm_context}

[ì§€ì¹¨]
- ìœ„ ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
- ì •ë³´ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  "ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
- í• ì¸ ì •ë³´ê°€ ìˆë‹¤ë©´ ëª…í™•í•˜ê²Œ ê°•ì¡°í•˜ì„¸ìš”.
- ê±°ë¦¬ ì •ë³´ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì•ˆë‚´í•˜ì„¸ìš”.
- ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.""",
                },
            ]
            if filter_result:
                messages.append(
                    {
                        "role": "system",
                        "content": f"ì¶”ê°€ ì°¸ì¡°: {json.dumps(filter_result, ensure_ascii=False)}",
                    }
                )
            
            # 3. User Message: ì‚¬ìš©ì ì§ˆë¬¸
            messages.append({
                "role": "user",
                "content": user_query
            })
            
            # OpenAI API í˜¸ì¶œ (ê³µì‹ ë¬¸ì„œ ê¸°ì¤€)
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo-1106",  # ìµœì‹  ëª¨ë¸ (JSON mode ì§€ì›)
                messages=messages,
                temperature=0.7,  # ì°½ì˜ì„± (0.0 ~ 2.0)
                max_tokens=800,   # ìµœëŒ€ í† í° ìˆ˜
                top_p=1.0,        # Nucleus sampling
                frequency_penalty=0.0,  # ë°˜ë³µ ê°ì†Œ
                presence_penalty=0.0,   # ì£¼ì œ ë‹¤ì–‘ì„±
                # response_format={"type": "text"}  # ë˜ëŠ” "json_object"
            )
            
            # ì‘ë‹µ ì¶”ì¶œ
            assistant_message = response.choices[0].message.content
            
            # í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…
            usage = response.usage
            print(f"ğŸ’° í† í° ì‚¬ìš©ëŸ‰: ì…ë ¥ {usage.prompt_tokens}, ì¶œë ¥ {usage.completion_tokens}, ì´ {usage.total_tokens}")
            
            return assistant_message
            
        except Exception as e:
            # ìƒì„¸í•œ ì—ëŸ¬ ì²˜ë¦¬
            error_type = type(e).__name__
            error_message = str(e)
            
            print(f"âŒ OpenAI API ì˜¤ë¥˜ [{error_type}]: {error_message}")
            
            # ì‚¬ìš©ì ì¹œí™”ì  ì—ëŸ¬ ë©”ì‹œì§€
            if "rate_limit" in error_message.lower():
                return "âš ï¸ ì¼ì‹œì ìœ¼ë¡œ ìš”ì²­ì´ ë§ì•„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            elif "invalid_api_key" in error_message.lower():
                return "âš ï¸ API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
            elif "insufficient_quota" in error_message.lower():
                return "âš ï¸ API ì‚¬ìš©ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
            else:
                return f"âš ï¸ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n(ì˜¤ë¥˜: {error_type})"
    
        
        return response


# ============================================================
# REST API ì„œë²„ ëª¨ë“œ (FastAPI)
# ============================================================

# Pydantic ëª¨ë¸ (API ìš”ì²­/ì‘ë‹µ)
if FASTAPI_AVAILABLE:
    class RecommendRequest(BaseModel):
        """LLM ê¸°ë°˜ ì¶”ì²œ ìš”ì²­ ëª¨ë¸"""
        query: str
        latitude: float
        longitude: float
        user_id: str  # í•„ìˆ˜ë¡œ ë³€ê²½!
        context: Optional[Dict[str, Any]] = None
        user_profile: Optional[Dict[str, Any]] = None
        
        class Config:
            json_schema_extra = {
                "example": {
                "query": "ê°•ë‚¨ì—­ ê·¼ì²˜ ë§›ì§‘ ì¶”ì²œí•´ì¤˜",
                "latitude": 37.5665,
                "longitude": 126.9780,
                "user_id": "user123",
                "user_profile": {
                    "telco": "SKT",
                    "memberships": ["VIP"],
                    "cards": ["T-Lounge"]
                }
            }
        }
    
    class RecommendResponse(BaseModel):
        """LLM ê¸°ë°˜ ì¶”ì²œ ì‘ë‹µ ëª¨ë¸"""
        success: bool
        query: str
        response: str
        mcp_results: Optional[Dict[str, Any]] = None
        error: Optional[str] = None


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
location_server = LocationServer()
llm_engine = LLMEngine()

# FastAPI ì•± ìƒì„±
if FASTAPI_AVAILABLE:
    app = FastAPI(
        title="ìœ„ì¹˜ ê¸°ë°˜ í• ì¸ ì„œë¹„ìŠ¤ API",
        description="Flutter ì•±ê³¼ MCP Serverë¥¼ ì—°ê²°í•˜ëŠ” REST API",
        version="1.0.0",
        # ë³´ì•ˆ: Swagger ë¬¸ì„œ ë¹„í™œì„±í™” (ì™¸ë¶€ ë…¸ì¶œ ë°©ì§€)
        docs_url=None,  # /docs ë¹„í™œì„±í™”
        redoc_url=None  # /redoc ë¹„í™œì„±í™”
    )
    
    # CORS ì„¤ì • (ëª¨ë°”ì¼ ì•± ì§€ì›)
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],  # ëª¨ë“  origin í—ˆìš© (ëª¨ë°”ì¼ 5G, WiFi ë“±)
        allow_credentials=True,
        allow_methods=["POST", "GET", "OPTIONS"],
        allow_headers=["Content-Type", "X-API-Key"],
    )
    
    # IP/í¬íŠ¸ ê¸°ë°˜ ì ‘ê·¼ ì œì–´ ë¯¸ë“¤ì›¨ì–´
    @app.middleware("http")
    async def access_control_middleware(request: Request, call_next):
        """IP/í¬íŠ¸ ê¸°ë°˜ ì ‘ê·¼ ì œì–´"""
        # ê°œë°œì ëª¨ë“œê°€ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ëª¨ë“  ì ‘ê·¼ í—ˆìš©
        if ACCESS_CONFIG.get("developer_mode", True):
            response = await call_next(request)
            return response
        
        # í´ë¼ì´ì–¸íŠ¸ IP ì¶”ì¶œ
        client_ip = request.client.host if request.client else "unknown"
        
        # IP í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì²´í¬
        if ACCESS_CONFIG.get("enable_ip_whitelist", False):
            allowed_ips = ACCESS_CONFIG.get("allowed_ips", [])
            if client_ip not in allowed_ips and "localhost" not in client_ip:
                return HTTPException(
                    status_code=403,
                    detail=f"ì ‘ê·¼ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. í—ˆìš©ëœ IP: {', '.join(allowed_ips)}"
                )
        
        # í¬íŠ¸ ì²´í¬ëŠ” ì„œë²„ ì‹œì‘ ì‹œì ì—ë§Œ ê°€ëŠ¥í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¡œê¹…ë§Œ
        response = await call_next(request)
        return response
    
    # ì •ì  íŒŒì¼ ì„œë¹™ (ì›¹ UI)
    static_dir = os.path.join(os.path.dirname(__file__), "static")
    if os.path.exists(static_dir):
        app.mount("/static", StaticFiles(directory=static_dir), name="static")
    
    # ì›¹ UI ë¼ìš°íŠ¸
    @app.get("/", response_class=HTMLResponse)
    async def web_ui():
        """ì›¹ UI í™ˆí˜ì´ì§€"""
        ui_path = os.path.join(os.path.dirname(__file__), "static", "index.html")
        if os.path.exists(ui_path):
            return FileResponse(ui_path)
        else:
            return HTMLResponse("""
            <html>
                <head><title>ìœ„ì¹˜ ê¸°ë°˜ í• ì¸ ì„œë¹„ìŠ¤</title></head>
                <body>
                    <h1>ìœ„ì¹˜ ê¸°ë°˜ í• ì¸ ì„œë¹„ìŠ¤ API</h1>
                    <p>ì›¹ UI íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. static/index.html íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.</p>
                    <p>API ì—”ë“œí¬ì¸íŠ¸: <a href="/ping">/ping</a></p>
                </body>
            </html>
            """)
    
    # API í‚¤ ê²€ì¦ í•¨ìˆ˜ (ì£¼ìš” ë³´ì•ˆ ìˆ˜ë‹¨)
    async def verify_api_key(x_api_key: str = Header(None)):
        """API í‚¤ ê²€ì¦ (ë³´í˜¸ëœ ì—”ë“œí¬ì¸íŠ¸ìš©)"""
        if not x_api_key:
            raise HTTPException(
                status_code=401,
                detail="API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. Headerì— X-API-Keyë¥¼ í¬í•¨í•˜ì„¸ìš”."
            )
        
        if x_api_key != API_KEY:
            raise HTTPException(
                status_code=403,
                detail="ìœ íš¨í•˜ì§€ ì•Šì€ API í‚¤ì…ë‹ˆë‹¤"
            )
        return x_api_key
    
    @app.get("/ping")
    async def ping():
        """
        ì´ˆê°„ë‹¨ ì—°ê²° í™•ì¸ (PowerShell pingê³¼ ìœ ì‚¬)
        
        íŒ€ì›ë“¤ì´ ê°€ì¥ ë¨¼ì € í…ŒìŠ¤íŠ¸í•´ì•¼ í•  ì—”ë“œí¬ì¸íŠ¸
        ìµœì†Œí•œì˜ ì‘ë‹µë§Œ ë°˜í™˜í•˜ì—¬ ë¹ ë¥´ê²Œ í™•ì¸
        """
        return {"pong": True}
    
    
    @app.post("/api/recommend", response_model=RecommendResponse)
    async def recommend_with_llm(
        request: RecommendRequest,
        api_key: str = Depends(verify_api_key)
    ):
        """
        LLM ê¸°ë°˜ ê°œì¸í™” ì¶”ì²œ API (API í‚¤ í•„ìš”)
        
        1. Prompt Filter
        2. LocationServer
        3. DiscountServer 
        4. RecommendationServer 
        5. RAG
        6. OpenAI LLM
        
        **í•„ìˆ˜ íŒŒë¼ë¯¸í„°**:
        - user_id: ì‚¬ìš©ì ID (ê°œì¸í™”ë¥¼ ìœ„í•´ í•„ìˆ˜!)
        - query: ìì—°ì–´ ì§ˆë¬¸
        - latitude, longitude: í˜„ì¬ ìœ„ì¹˜
        
        Header: X-API-Key: OSS_TEAM_SECRET_KEY_2025
        
        Args:
            request: ì¶”ì²œ ìš”ì²­ (ì§ˆë¬¸, ìœ„ë„, ê²½ë„, ì‚¬ìš©ìID ë“±)
        
        Returns:
            LLM ì‘ë‹µ
        
        Example:
            {
                "query": "ê°•ë‚¨ì—­ ê·¼ì²˜ ë§›ì§‘ ì¶”ì²œí•´ì¤˜. í• ì¸ ë§ì´ ë°›ì„ ìˆ˜ ìˆëŠ” ê³³ìœ¼ë¡œ",
                "latitude": 37.5665,
                "longitude": 126.9780,
                "user_id": "user123"
            }
        """
        try:
            ## mode ë³„ë¡œ êµ¬í˜„ ë˜ëŠ” ë‹¨ê³„ì˜ ê¹Šì´ê°€ ë‹¤ë¥´ê²Œ ì„¤ì •í•¨.
            # mode = {prompt,location,discount,recommendation,rag}
            # mode = [1,0,0,0,0]  # prompt filter ê¹Œì§€ë§Œ
            # mode = [1,1,0,0,0]  # location server ê¹Œì§€ë§Œ
            # mode = [1,1,1,0,0]  # discount server ê¹Œì§€ë§Œ
            # mode = [1,1,1,1,0]  # recommendation server ê¹Œì§€ë§Œ
            # mode = [1,1,1,1,1]  # rag ê¹Œì§€ ëª¨ë‘
            result = await llm_engine.process_query(
                user_query=request.query,
                latitude=request.latitude,
                longitude=request.longitude,
                user_id=request.user_id,
                user_profile=request.user_profile, ## user_profile ë„˜ê²¨ë°›ëŠ” ë¶€ë¶„ ì¶”ê°€
                mode=[1,0,0,0,0]  # prompt filter ê¹Œì§€ë§Œ í…ŒìŠ¤íŠ¸
            )
            
            if not result["success"]:
                return RecommendResponse(
                    success=False,
                    query=request.query,
                    response=result["response"],
                    error=result.get("error")
                )
            
            return RecommendResponse(
                success=True,
                query=request.query,
                response=result["response"],
                mcp_results=result.get("mcp_results")
            )
            
        except Exception as e:
            raise HTTPException(
                status_code=500,
                detail=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}"
            )



# ============================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================

def main():
    """ë©”ì¸ ì§„ì…ì """
    parser = argparse.ArgumentParser(description="ìœ„ì¹˜ ê¸°ë°˜ í• ì¸ ì„œë¹„ìŠ¤ MCP Client")
    parser.add_argument(
        "--mode",
        choices=["api", "test"],
        default="test",
        help="ì‹¤í–‰ ëª¨ë“œ: api (REST API ì„œë²„) ë˜ëŠ” test (í…ŒìŠ¤íŠ¸)"
    )
    parser.add_argument(
        "--host",
        default="145.0.0.0",
        help="API ì„œë²„ í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸: 145.0.0.0)"
    )
    parser.add_argument(
        "--port",
        type=int,
        default=8000,
        help="API ì„œë²„ í¬íŠ¸ (ê¸°ë³¸: 8000)"
    )
    
    args = parser.parse_args()
    
    if args.mode == "api":
        if not FASTAPI_AVAILABLE:
            print("âŒ FastAPIê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   ì‹¤í–‰: pip install fastapi uvicorn pydantic")
            sys.exit(1)
        
       
        
        public_ip = "115.68.232.165"  # ì‹¤ì œ ë¦¬ëˆ…ìŠ¤ ì„œë²„ ê³µì¸ IP
        print("ğŸš€ REST API ì„œë²„ ì‹œì‘...")
        print(f"   ë°”ì¸ë“œ ì£¼ì†Œ: {args.host}")
        print(f"\nğŸ“± Flutter ì•± ì ‘ì† ì£¼ì†Œ:")
        print(f"   â–¶ http://{public_ip}/api/recommend")
        print(f"\nğŸ”§ ê°œë°œì í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸:")
        print(f"   â–¶ GET  http://localhost:{args.port}/ping")
        print(f"   â–¶ GET  http://localhost:{args.port}/api/health")
        print(f"   â–¶ GET  http://localhost:{args.port}/api/test")
        print(f"\nğŸ’¡ ì°¸ê³ :")
        print(f"   - Flutter ì•±ì€ /api/recommend ì—”ë“œí¬ì¸íŠ¸ë§Œ ì‚¬ìš©")
        print(f"   - user_idëŠ” í•„ìˆ˜ íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤")
        print(f"   - API ë¬¸ì„œ(Swagger)ëŠ” ë³´ì•ˆìƒ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
        print("\n" + "=" * 60)
        
        uvicorn.run(app, host=args.host, port=args.port)
    


if __name__ == "__main__":
    main()

import asyncio
import importlib.util
import json
import logging
import re
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import aiohttp

# location_server_config.py íŒŒì¼ì´ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
from location_server_config import (
    NAVER_SEARCH_CLIENT_ID,
    NAVER_SEARCH_CLIENT_SECRET,
    NAVER_APP_CLIENT_ID,
    NAVER_APP_CLIENT_SECRET,
    NAVER_GEOCODE_URL,
)

# review_crawler.py íŒŒì¼ì´ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
from review_crawler import ReviewCrawler, NaverPlaceAPIClient

logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s:%(name)s: %(message)s',
    stream=sys.stderr,
    force=True
)
logger = logging.getLogger(__name__)

DEFAULT_RESULTS = 5
REVIEWS_PER_STORE = 3


@dataclass
class QueryIntent:
    original_query: str
    place_type: str
    attributes: List[str]
    location: Optional[str]


ATTRIBUTE_KEYWORDS: Dict[str, str] = {
    "ë§›ìˆëŠ”": "ë§›ìˆëŠ”",
    "ì•¼ì‹": "ì•¼ì‹",
    "ë¶„ìœ„ê¸°ì¢‹ì€": "ë¶„ìœ„ê¸° ì¢‹ì€",
    "ê´œì°®ì€": "ê´œì°®ì€",
    "1ì¸ë¶„ì£¼ë¬¸ê°€ëŠ¥": "1ì¸ë¶„",
    "ë°°ë‹¬": "ë°°ë‹¬",
    "ì‹ ê·œ": "ì‹ ê·œ",
    "íšŒì‹": "íšŒì‹",
    "ë¶€ëª¨ë‹˜": "ë¶€ëª¨ë‹˜ ëª¨ì‹œê¸°",
    "ê°€ì„±ë¹„ì¢‹ì€": "ê°€ì„±ë¹„",
    "ëœ¨ëˆí•œ": "ëœ¨ëˆí•œ",
    "íŠ¹ë³„í•œë‚ ": "íŠ¹ë³„í•œ ë‚ ",
    "ì•„ì¹¨": "ì•„ì¹¨",
    "ìˆ¨ê²¨ì§„": "ìˆ¨ê²¨ì§„",
    "ë°˜ì°¬": "ë°˜ì°¬",
    "í¬ì¥": "í¬ì¥",
    "ë‹¤íšŒìš©ê¸°": "ë‹¤íšŒìš©ê¸°",
    "ì•¼ì™¸": "ì•¼ì™¸ í…Œë¼ìŠ¤",
    "ì• ê²¬ë™ë°˜": "ì• ê²¬ë™ë°˜",
}

PLACE_TYPE_MAPPING: Dict[str, str] = {
    "ì¹´í˜": "ì¹´í˜",
    "ì¹´í˜/ë””ì €íŠ¸": "ë””ì €íŠ¸ ì¹´í˜",
    "ë§›ì§‘": "ë§›ì§‘",
    "í•œì‹": "í•œì‹",
    "í”¼ì/ì–‘ì‹": "ì–‘ì‹",
    "ì°œ/íƒ•": "ì°œ",
    "ë„ì‹œë½/ì£½": "ë„ì‹œë½",
    "ì¼ì‹/ëˆê¹ŒìŠ¤": "ëˆê¹ŒìŠ¤",
    "ì¹˜í‚¨": "ì¹˜í‚¨",
    "íšŒ/ì´ˆë°¥": "ì´ˆë°¥",
    "ì¼ì‹": "ì´ìì¹´ì•¼",
    "ë¶„ì‹": "ë¶„ì‹",
    "ì¡±ë°œ/ë³´ìŒˆ": "ì¡±ë°œ",
    "ì¤‘ì‹": "ì¤‘ì‹",
    "ê³ ê¸°/êµ¬ì´": "ê³ ê¸° êµ¬ì´",
    "ìƒëŸ¬ë“œ": "ìƒëŸ¬ë“œ",
    "íŒ¨ìŠ¤íŠ¸í‘¸ë“œ": "ë²„ê±°",
    "ì•„ì‹œì•ˆ": "ì•„ì‹œì•ˆ",
    "ìˆ ì§‘": "ìˆ ì§‘",
}


def attribute_keywords(attributes: List[str]) -> str:
    words = [ATTRIBUTE_KEYWORDS.get(attr, "") for attr in attributes]
    return " ".join(word for word in words if word)


def map_place_type(place_type: str) -> str:
    return PLACE_TYPE_MAPPING.get(place_type, place_type)


def resolve_search_terms(intent: QueryIntent) -> Tuple[str, str]:
    place_keyword = map_place_type(intent.place_type)
    parts: List[str] = []
    if intent.location:
        parts.append(intent.location)
    if place_keyword:
        parts.append(place_keyword)
    attr = attribute_keywords(intent.attributes)
    if attr:
        parts.append(attr)
    if not parts:
        parts.append(intent.original_query)
    search_keyword = " ".join(parts)
    return search_keyword, place_keyword


async def load_test_queries() -> Tuple[List[str], Any]:
    # í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ì—ì„œ ë¶€ëª¨ í´ë”ë¥¼ ì°¾ê¸° ìœ„í•œ ê¸°ì¤€ ê²½ë¡œ ì„¤ì •
    project_root = Path(__file__).resolve().parents[2]
    
    # test_real_user_queries.py íŒŒì¼ ê²½ë¡œ ì„¤ì •
    test_module_path = project_root / ".vscode" / "android_discount_app" / "test_real_user_queries.py"
    
    # test_real_user_queries.py íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©
    if test_module_path.exists():
        spec = importlib.util.spec_from_file_location("test_real_user_queries", test_module_path)
        if spec is None or spec.loader is None:
            raise RuntimeError("test_real_user_queries.py ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)  # type: ignore[attr-defined]
        
        queries = getattr(module, "test_queries", None)
        extractor = getattr(module, "_extract_keywords_fallback", None)
        if not queries or not extractor:
            raise RuntimeError("í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ë˜ëŠ” í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return queries, extractor
    
    # íŒŒì¼ì´ ì—†ìœ¼ë©´ query_results.jsonì—ì„œ ì¿¼ë¦¬ë¥¼ ì½ê³  chat_filter_pipelineì—ì„œ extractor ê°€ì ¸ì˜¤ê¸°
    logger.info("test_real_user_queries.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ query_results.jsonì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    # query_results.jsonì—ì„œ ì¿¼ë¦¬ ì¶”ì¶œ (query_to_naver.pyì™€ ê°™ì€ í´ë”ì— ìˆë‹¤ê³  ê°€ì •)
    results_path = Path(__file__).with_name("query_results.json")
    if not results_path.exists():
        raise FileNotFoundError(f"query_results.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {results_path}")
    
    with open(results_path, "r", encoding="utf-8") as f:
        results = json.load(f)
    
    # query_results.jsonì˜ ê° í•­ëª©ì—ì„œ original_query ì¶”ì¶œ
    queries = [result.get("intent", {}).get("original_query") for result in results if result.get("intent", {}).get("original_query")]
    if not queries:
        raise RuntimeError("query_results.jsonì—ì„œ ì¿¼ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # chat_filter_pipeline.pyì—ì„œ extractor ê°€ì ¸ì˜¤ê¸°
    # í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ ê°€ì •í•˜ì—¬, 'Location_server'ì˜ ë¶€ëª¨ í´ë”(project_root.parents[1])ì˜ í˜•ì œ í´ë”ì¸ 'mcp-client'ì— ìˆë‹¤ê³  ì¶”ì •
    pipeline_path = project_root.parents[1] / "mcp-client" / "chat_filter_pipeline.py"
    if not pipeline_path.exists():
        # ë§Œì•½ ê²½ë¡œê°€ ë‹¬ëë‹¤ë©´, í˜„ì¬ íŒŒì¼ì˜ ë¶€ëª¨ì˜ ë¶€ëª¨ í´ë”ë¡œ ë‹¤ì‹œ ì‹œë„
        pipeline_path = project_root / "mcp-client" / "chat_filter_pipeline.py"
        if not pipeline_path.exists():
            raise FileNotFoundError(f"chat_filter_pipeline.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pipeline_path}")
    
    logger.info(f"âœ… chat_filter_pipeline.py ë¡œë“œ ê²½ë¡œ: {pipeline_path}")
    
    spec = importlib.util.spec_from_file_location("chat_filter_pipeline", pipeline_path)
    if spec is None or spec.loader is None:
        raise RuntimeError("chat_filter_pipeline.py ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)  # type: ignore[attr-defined]
    
    extractor = getattr(module, "_extract_keywords_fallback", None)
    if not extractor:
        raise RuntimeError("chat_filter_pipeline.pyì—ì„œ _extract_keywords_fallback í•¨ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    logger.info(f"âœ… query_results.jsonì—ì„œ {len(queries)}ê°œì˜ ì¿¼ë¦¬ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    return queries, extractor


def extract_place_id(link: str) -> Optional[str]:
    match = re.search(r"/place/(\d+)", link)
    if match:
        return match.group(1)
    match = re.search(r"placeId=(\d+)", link)
    if match:
        return match.group(1)
    return None


async def search_places(
    naver_client: NaverPlaceAPIClient,
    intent: QueryIntent,
    center: Optional[Tuple[float, float]] = None,
) -> Dict[str, Any]:
    '''
    "ë„¤ì´ë²„ ì§€ì—­ ê²€ìƒ‰ APIë¡œ ì¥ì†Œ ê²€ìƒ‰"
    '''
    search_keyword, place_keyword = resolve_search_terms(intent)
    
    # ë„¤ì´ë²„ ê²€ìƒ‰ API í˜¸ì¶œ (ì¢Œí‘œê°€ ìˆìœ¼ë©´ í™œìš©)
    documents = await naver_client.search_place(
        search_keyword,
        display=DEFAULT_RESULTS,
        lat=center[0] if center else None,
        lng=center[1] if center else None,
    )
    
    # ì‹¤ì œ ë¦¬ë·°ë§Œ ì‚¬ìš© (mock í´ë°± ì œê±°)
    crawler_real = ReviewCrawler(use_mock=False)
    
    stores: List[Dict[str, Any]] = []
    for item in documents:
        link = item.get("link", "")
        place_id = extract_place_id(link)
        
        store = {
            "id": place_id or item.get("title"),
            "name": re.sub(r"<.*?>", "", item.get("title", "")),
            "category": item.get("category"),
            "address": item.get("address"),
            "road_address": item.get("roadAddress"),
            "phone": item.get("telephone"),
            "place_url": link,
            "mapx": item.get("mapx"),
            "mapy": item.get("mapy"),
            "naver_place_id": place_id,
            "searched_keyword": search_keyword,
            "matched_place_keyword": place_keyword,
        }
        
        # ì‹¤ì œ ë¦¬ë·°ë§Œ ìˆ˜ì§‘ (mock í´ë°± ì œê±°)
        reviews: List[Dict[str, Any]] = []
        if place_id:
            reviews = await crawler_real.get_place_reviews(
                store_info=store,
                max_reviews=REVIEWS_PER_STORE,
                source="naver",
            )
            if reviews:
                logger.info(f"{store['name']}: ì‹¤ì œ ë¦¬ë·° {len(reviews)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
        
        store["reviews"] = reviews  # ë¦¬ë·°ê°€ ì—†ì–´ë„ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
        stores.append(store)
    
    # nearby_reviews.py í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    stores_list = []
    reviews_dict = {}
    
    for store in stores:
        store_name = store.get("name", "")
        if store_name:
            stores_list.append(store_name)
            # ë¦¬ë·° í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
            review_texts = [
                review.get("review_text", review.get("content", review.get("text", ""))).strip()
                for review in store.get("reviews", [])
                if review.get("review_text", review.get("content", review.get("text", ""))).strip()
            ]
            if review_texts:
                reviews_dict[store_name] = review_texts
    
    result: Dict[str, Any] = {
        "intent": {
            "original_query": intent.original_query,
            "place_type": intent.place_type,
            "attributes": intent.attributes,
            "location": intent.location,
            "search_keyword": search_keyword,
        },
        "total_count": len(stores_list),
        "stores": stores_list,
        "reviews": reviews_dict,
    }
    
    # ì§€ì˜¤ì½”ë”© ê²°ê³¼ê°€ ìˆìœ¼ë©´ center ê°’ ì¶”ê°€
    if center:
        result["center"] = {"latitude": center[0], "longitude": center[1]}
    else:
        result["center"] = None
    
    return result


async def _try_geocode(session: aiohttp.ClientSession, location: str) -> Optional[Tuple[float, float]]:
    """ë‹¨ì¼ ìœ„ì¹˜ ë¬¸ìì—´ë¡œ ì§€ì˜¤ì½”ë”© APIë¥¼ í†µí•œ ì§€ì˜¤ì½”ë”© ì‹œë„"""
    if not (NAVER_APP_CLIENT_ID and NAVER_APP_CLIENT_SECRET):
        return None
    
    headers = {
        "X-NCP-APIGW-API-KEY-ID": NAVER_APP_CLIENT_ID,
        "X-NCP-APIGW-API-KEY": NAVER_APP_CLIENT_SECRET,
    }
    params = {"query": location}
    
    try:
        async with session.get(NAVER_GEOCODE_URL, headers=headers, params=params) as response:
            if response.status != 200:
                return None
            data = await response.json()
    except Exception:
        return None
    
    addresses = data.get("addresses") or []
    if not addresses:
        return None
    
    first = addresses[0]
    try:
        latitude = float(first.get("y"))
        longitude = float(first.get("x"))
        return latitude, longitude
    except (TypeError, ValueError):
        return None


async def _geocode_via_search_api(
    session: aiohttp.ClientSession,
    naver_client: NaverPlaceAPIClient,
    location: str
) -> Optional[Tuple[float, float]]:
    """ë„¤ì´ë²„ ì§€ì—­ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ„ì¹˜ë¥¼ ê²€ìƒ‰í•˜ê³  ìœ„ë„/ê²½ë„ë¥¼ ì¶”ì¶œ"""
    try:
        # ë„¤ì´ë²„ ì§€ì—­ ê²€ìƒ‰ APIë¡œ ìœ„ì¹˜ ê²€ìƒ‰
        documents = await naver_client.search_place(
            location,
            display=5,  # ì—¬ëŸ¬ ê²°ê³¼ ì¤‘ ìµœì ì˜ ê²ƒì„ ì„ íƒ
        )
        
        if not documents:
            return None
        
        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì£¼ì†Œ ì¶”ì¶œ í›„ ì§€ì˜¤ì½”ë”© ì‹œë„
        for result in documents:
            # roadAddress ë˜ëŠ” address ì¶”ì¶œ
            address = result.get("roadAddress") or result.get("address")
            if address:
                # ì£¼ì†Œë¡œ ì§€ì˜¤ì½”ë”© API í˜¸ì¶œ
                coords = await _try_geocode(session, address)
                if coords:
                    logger.debug(f"ê²€ìƒ‰ API ê²°ê³¼ë¡œ ì§€ì˜¤ì½”ë”© ì„±ê³µ: {location} -> {address} -> {coords}")
                    return coords
        
        return None
    except Exception as e:
        logger.debug(f"ê²€ìƒ‰ APIë¥¼ í†µí•œ ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨: {location}, {e}")
        return None


async def geocode_location(
    session: aiohttp.ClientSession,
    location: str,
    naver_client: Optional[NaverPlaceAPIClient] = None
) -> Optional[Tuple[float, float]]:
    """ìœ„ì¹˜ ë¬¸ìì—´ì„ ë„¤ì´ë²„ ì§€ë„ ì§€ì˜¤ì½”ë”© API ë˜ëŠ” ê²€ìƒ‰ APIë¡œ ìœ„Â·ê²½ë„ ì¢Œí‘œë¡œ ë³€í™˜
    
    1. ë¨¼ì € ì§€ì˜¤ì½”ë”© APIë¡œ ì›ë³¸ ìœ„ì¹˜ëª… ì§ì ‘ ì‹œë„
    2. ì‹¤íŒ¨ ì‹œ ë„¤ì´ë²„ ì§€ì—­ ê²€ìƒ‰ APIë¡œ ìœ„ì¹˜ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì£¼ì†Œ ì¶”ì¶œ í›„ ì§€ì˜¤ì½”ë”©
    """
    if not location or not location.strip():
        logger.warning("ìœ„ì¹˜ ë¬¸ìì—´ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return None
    
    # 'ì´ ê·¼ì²˜'ì™€ ê°™ì€ ìƒëŒ€ ì£¼ì†ŒëŠ” ì§€ì˜¤ì½”ë”© APIê°€ ì²˜ë¦¬í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ê±´ë„ˆëœë‹ˆë‹¤.
    if location.strip() in ["ì´ ê·¼ì²˜", "ì—¬ê¸°", "ê·¼ì²˜"]:
        logger.warning(f"ìƒëŒ€ì ì¸ ìœ„ì¹˜ ë¬¸ìì—´ì€ ì§€ì˜¤ì½”ë”©ì„ ê±´ë„ˆëœë‹ˆë‹¤: {location}")
        return None
    
    location = location.strip()

    # 1ë‹¨ê³„: ì§€ì˜¤ì½”ë”© APIë¡œ ì›ë³¸ ìœ„ì¹˜ëª… ì§ì ‘ ì‹œë„
    if NAVER_APP_CLIENT_ID and NAVER_APP_CLIENT_SECRET:
        result = await _try_geocode(session, location)
        if result:
            logger.info(f"ì§€ì˜¤ì½”ë”© ì„±ê³µ: {location} -> {result}")
            return result
    
    # 2ë‹¨ê³„: ì§€ì˜¤ì½”ë”© API ì‹¤íŒ¨ ì‹œ ë„¤ì´ë²„ ì§€ì—­ ê²€ìƒ‰ APIë¡œ ì‹œë„
    if naver_client:
        result = await _geocode_via_search_api(session, naver_client, location)
        if result:
            logger.info(f"ì§€ì˜¤ì½”ë”© ì„±ê³µ (ê²€ìƒ‰ API ì‚¬ìš©): {location} -> {result}")
            return result
    
        logger.warning(f"ì§€ì˜¤ì½”ë”© ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. location={location}")
        return None


async def process_queries() -> List[Dict[str, Any]]:
    if not (NAVER_SEARCH_CLIENT_ID and NAVER_SEARCH_CLIENT_SECRET):
        raise RuntimeError("NAVER_SEARCH_CLIENT_ID/SECRETê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    queries, extractor = await load_test_queries()
    intents: List[QueryIntent] = []
    for q in queries:
        keywords = extractor(q)
        intents.append(
            QueryIntent(
                original_query=q,
                place_type=keywords.get("place_type") or "ë§›ì§‘",
                attributes=keywords.get("attributes") or [],
                location=keywords.get("location"),
            )
        )
    
    naver_client = NaverPlaceAPIClient(
        client_id=NAVER_SEARCH_CLIENT_ID,
        client_secret=NAVER_SEARCH_CLIENT_SECRET,
    )
    
    results: List[Dict[str, Any]] = []
    async with aiohttp.ClientSession() as session:
        for intent in intents:
            center: Optional[Tuple[float, float]] = None
            if intent.location:
                center = await geocode_location(session, intent.location, naver_client=naver_client)
            
            try:
                result = await search_places(naver_client, intent, center=center)
                results.append(result)
            except Exception as exc:
                logger.error("âŒ ê²€ìƒ‰ ì²˜ë¦¬ ì‹¤íŒ¨: %s", exc)
                results.append(
                    {
                        "intent": {
                            "original_query": intent.original_query,
                            "error": str(exc),
                        }
                    }
                )
    
    return results


def main() -> None:
    print("ğŸš€ query_to_naver.py ì‹¤í–‰ ì‹œì‘", flush=True)
    logger.info("ğŸš€ query_to_naver.py ì‹¤í–‰ ì‹œì‘")
    
    try:
        results = asyncio.run(process_queries())
        output_path = Path(__file__).with_name("query_results.json")
        output_path.write_text(
            json.dumps(results, ensure_ascii=False, indent=2),
            encoding="utf-8",
        )
        print(f"âœ… ê²°ê³¼ë¥¼ {output_path} íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.", flush=True)
        logger.info(f"âœ… ê²°ê³¼ë¥¼ {output_path} íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}", flush=True, file=sys.stderr)
        logger.exception("âŒ ì˜¤ë¥˜ ë°œìƒ")
        raise


if __name__ == "__main__":
    main()
